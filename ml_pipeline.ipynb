{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea231131",
   "metadata": {},
   "source": [
    "# Credit Card Default Prediction - ML Pipeline\n",
    "\n",
    "This notebook contains the complete machine learning pipeline for predicting credit card defaults."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ca3fa",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3b37a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import warnings\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (\n",
    "\troc_auc_score, precision_score, recall_score, f1_score,\n",
    "\tconfusion_matrix, average_precision_score, brier_score_loss, accuracy_score, classification_report\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.base import clone\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats.mstats import winsorize\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fe9955",
   "metadata": {},
   "source": [
    "## Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11e37446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats.mstats import winsorize\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def preprocess_data(file_path, verbose=False, apply_scaling=False, split_data=False, apply_smote=False, test_size=0.2, random_state=42):\n",
    "\t\"\"\"\n",
    "\tPreprocess the credit card default dataset.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tfile_path: Path to the Excel file containing the dataset\n",
    "\t\tverbose: If True, print progress information. If False, no output.\n",
    "\t\tapply_scaling: If True, apply robust scaling (robust if anomalies present, else standard)\n",
    "\t\tsplit_data: If True, return train/test split. If False, return single DataFrame\n",
    "\t\tapply_smote: If True, apply SMOTE to training data (only works if split_data=True)\n",
    "\t\ttest_size: Proportion of dataset to use for testing (default 0.2)\n",
    "\t\trandom_state: Random seed for reproducibility\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tIf split_data=False: Preprocessed pandas DataFrame\n",
    "\t\tIf split_data=True: (X_train, X_test, y_train, y_test, scaler) tuple\n",
    "\t\t\tscaler will be None if apply_scaling=False, otherwise the fitted scaler object\n",
    "\t\"\"\"\n",
    "\t# Helper function for conditional printing\n",
    "\tdef log(*args, **kwargs):\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(*args, **kwargs)\n",
    "\t\n",
    "\t# Load the dataset\n",
    "\tdf = pd.read_excel(file_path)\n",
    "\t\n",
    "\t# Rename columns to their descriptive names\n",
    "\tcolumn_mapping = {\n",
    "\t\t'X1': 'LIMIT_BAL',\n",
    "\t\t'X2': 'SEX',\n",
    "\t\t'X3': 'EDUCATION',\n",
    "\t\t'X4': 'MARRIAGE',\n",
    "\t\t'X5': 'AGE',\n",
    "\t\t'X6': 'PAY_0',\n",
    "\t\t'X7': 'PAY_2',\n",
    "\t\t'X8': 'PAY_3',\n",
    "\t\t'X9': 'PAY_4',\n",
    "\t\t'X10': 'PAY_5',\n",
    "\t\t'X11': 'PAY_6',\n",
    "\t\t'X12': 'BILL_AMT1',\n",
    "\t\t'X13': 'BILL_AMT2',\n",
    "\t\t'X14': 'BILL_AMT3',\n",
    "\t\t'X15': 'BILL_AMT4',\n",
    "\t\t'X16': 'BILL_AMT5',\n",
    "\t\t'X17': 'BILL_AMT6',\n",
    "\t\t'X18': 'PAY_AMT1',\n",
    "\t\t'X19': 'PAY_AMT2',\n",
    "\t\t'X20': 'PAY_AMT3',\n",
    "\t\t'X21': 'PAY_AMT4',\n",
    "\t\t'X22': 'PAY_AMT5',\n",
    "\t\t'X23': 'PAY_AMT6',\n",
    "\t\t'Y': 'default_payment_next_month'\n",
    "\t}\n",
    "\t\n",
    "\t# Filter mapping to only include columns that exist, then rename all at once\n",
    "\t# (Learned this trick on leetcode)\n",
    "\tfiltered_mapping = {old: new for old, new in column_mapping.items() if old in df.columns}\n",
    "\tif filtered_mapping:\n",
    "\t\tdf = df.rename(columns=filtered_mapping)\n",
    "\t\tlog(\"Renamed columns:\")\n",
    "\t\tfor old_name, new_name in filtered_mapping.items():\n",
    "\t\t\tlog(f\"  {old_name} -> {new_name}\")\n",
    "\t\tlog()\n",
    "\t\n",
    "\t\"\"\"\n",
    "\tLoad and check the dataset\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tlog(\"INITIAL DATA EXPLORATION\")\n",
    "\t\n",
    "\tlog(f\"\\nDataFrame head:\\n{df.head()}\")\n",
    "\t\n",
    "\t\n",
    "\tlog(f\"\\nDataFrame tail:\\n{df.tail()}\")\n",
    "\t\n",
    "\tlog(f\"\\nDataFrame info:\\n{df.info()}\")\n",
    "\t\n",
    "\tlog(f\"\\nDataFrame describe:\\n{df.describe()}\")\n",
    "\t\n",
    "\tlog(f\"\\nDataFrame shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\tlog(f\"Expected size: ~30,000 rows\")\n",
    "\tif df.shape[0] < 2500: # Minimum requirement of 2,500 rows\n",
    "\t\tlog(\"WARNING: Dataset size below minimum requirement of 2,500 rows\")\n",
    "\telif 25000 <= df.shape[0] <= 35000:\n",
    "\t\tlog(\"Dataset size looks good\")\n",
    "\telse:\n",
    "\t\tlog(f\"Dataset size: {df.shape[0]} rows (expected ~30,000)\")\n",
    "\t\n",
    "\tlog(f\"\\nDataFrame columns:\\n{df.columns.tolist()}\")\n",
    "\tlog(df.columns.tolist())\n",
    "\t\n",
    "\tlog(f\"\\nDataFrame dtypes:\\n{df.dtypes}\")\n",
    "\t\n",
    "\tlog(f\"\\nMissing values count:\\n{df.isna().sum()}\")\n",
    "\tmissing_counts = df.isna().sum()\n",
    "\tlog(missing_counts[missing_counts > 0])\n",
    "\t\n",
    "\tlog(f\"\\nDuplicate rows:\\n{df.duplicated().sum()}\")\n",
    "\t\n",
    "\t\"\"\"\n",
    "\tRemove unnecessary columns\n",
    "\t\"\"\"\n",
    "\tlog(\"REMOVING UNNECESSARY COLUMNS\")\n",
    "\t\n",
    "\t# Remove ID/index columns - they're not useful for prediction\n",
    "\t# Common names: ID, id, Unnamed: 0, index (default for excel files)\n",
    "\tcols_to_drop = []\n",
    "\tfor col in df.columns:\n",
    "\t\tcol_lower = str(col).lower()\n",
    "\t\tif col_lower in ['id', 'unnamed: 0', 'index'] or 'id' in col_lower:\n",
    "\t\t\tcols_to_drop.append(col)\n",
    "\t\n",
    "\tif cols_to_drop:\n",
    "\t\tlog(f\"Dropping columns: {cols_to_drop}\")\n",
    "\t\tdf = df.drop(columns=cols_to_drop)\n",
    "\telse:\n",
    "\t\tlog(\"No obvious index columns found to drop\")\n",
    "\t\n",
    "\tlog(\"HANDLING MISSING VALUES\")\n",
    "\t\n",
    "\tmissing_counts = df.isna().sum()\n",
    "\tmissing_cols = missing_counts[missing_counts > 0]\n",
    "\t\n",
    "\tif len(missing_cols) == 0:\n",
    "\t\tlog(\"No missing values found\")\n",
    "\telse:\n",
    "\t\tlog(f\"Columns with missing values: {len(missing_cols)}\")\n",
    "\t\t\n",
    "\t\t# First pass: drop columns with too many missing values (10% or more)\n",
    "\t\tcols_to_drop_missing = []\n",
    "\t\tfor col in missing_cols.index:  \n",
    "\t\t\tmissing_pct = (missing_counts[col] / len(df)) * 100\n",
    "\t\t\tif missing_pct >= 10:\n",
    "\t\t\t\tlog(f\"{col}: {missing_counts[col]} missing ({missing_pct:.2f}%) - Dropping column\")\n",
    "\t\t\t\tcols_to_drop_missing.append(col)\n",
    "\t\t\n",
    "\t\tif cols_to_drop_missing:\n",
    "\t\t\tlog(f\"\\nDropping columns with too many missing values: {cols_to_drop_missing}\")\n",
    "\t\t\tdf = df.drop(columns=cols_to_drop_missing)\n",
    "\t\t\tmissing_counts = df.isna().sum()\n",
    "\t\t\tmissing_cols = missing_counts[missing_counts > 0]\n",
    "\t\t\n",
    "\t\t# Check if we need KNN imputation (for numeric columns with >=10% missing)\n",
    "\t\tnumeric_cols_for_knn = []\n",
    "\t\tfor col in missing_cols.index:\n",
    "\t\t\tif df[col].dtype in ['int64', 'float64']:\n",
    "\t\t\t\tmissing_pct = (missing_counts[col] / len(df)) * 100\n",
    "\t\t\t\tif missing_pct >= 10:\n",
    "\t\t\t\t\tnumeric_cols_for_knn.append(col)\n",
    "\t\t\n",
    "\t\t# Handle KNN imputation for all numeric columns at once if needed\n",
    "\t\tif numeric_cols_for_knn:\n",
    "\t\t\tlog(f\"\\nUsing K-NN imputation for numeric columns with >=10% missing: {numeric_cols_for_knn}\")\n",
    "\t\t\timputer = KNNImputer(n_neighbors=5)\n",
    "\t\t\tnumeric_cols_all = df.select_dtypes(include=[np.number]).columns\n",
    "\t\t\tdf_numeric = df[numeric_cols_all].copy()\n",
    "\t\t\timputed = imputer.fit_transform(df_numeric)\n",
    "\t\t\tdf[numeric_cols_all] = imputed\n",
    "\t\t\t# Update missing counts after KNN\n",
    "\t\t\tmissing_counts = df.isna().sum()\n",
    "\t\t\tmissing_cols = missing_counts[missing_counts > 0]\n",
    "\t\t\n",
    "\t\t# Handle remaining missing values column by column\n",
    "\t\tfor col in missing_cols.index:\n",
    "\t\t\tmissing_pct = (missing_counts[col] / len(df)) * 100\n",
    "\t\t\tlog(f\"\\n{col}: {missing_counts[col]} missing ({missing_pct:.2f}%)\")\n",
    "\t\t\t\n",
    "\t\t\t# If insignificant count, just drop the rows\n",
    "\t\t\tif missing_pct < 1:\n",
    "\t\t\t\tlog(f\"  -> Dropping {missing_counts[col]} rows with missing values\")\n",
    "\t\t\t\tdf = df.dropna(subset=[col])\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Handle based on data type\n",
    "\t\t\t\tif df[col].dtype in ['int64', 'float64']:\n",
    "\t\t\t\t\t# Numeric: use mean (KNN already handled if needed)\n",
    "\t\t\t\t\tmean_val = df[col].mean()\n",
    "\t\t\t\t\tlog(f\"  -> Filling {missing_counts[col]} missing values with mean: {mean_val:.2f}\")\n",
    "\t\t\t\t\tdf[col] = df[col].fillna(mean_val)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t# Categorical: impute with mode\n",
    "\t\t\t\t\tmode_val = df[col].mode()[0] if len(df[col].mode()) > 0 else 'Unknown'\n",
    "\t\t\t\t\tlog(f\"  -> Filling {missing_counts[col]} missing values with mode: {mode_val}\")\n",
    "\t\t\t\t\tdf[col] = df[col].fillna(mode_val)\n",
    "\t\n",
    "\tlog(f\"\\nShape after handling missing values: {df.shape}\")\n",
    "\t\n",
    "\t\"\"\"\n",
    "\tCorrect types and encoding\n",
    "\t\"\"\"\n",
    "\tlog(\"CORRECTING TYPES AND ENCODING\")\n",
    "\t\n",
    "\t# Float -> Int (where values are whole numbers)\n",
    "\tfor col in df.select_dtypes(include=['float64']).columns:\n",
    "\t\tif df[col].notna().all():\n",
    "\t\t\tif (df[col] % 1 == 0).all():\n",
    "\t\t\t\tlog(f\"Converting {col} from float to int\")\n",
    "\t\t\t\tdf[col] = df[col].astype('int64')\n",
    "\t\n",
    "\t# String -> Int (where applicable - e.g., \"1\", \"2\" -> 1, 2)\n",
    "\tstring_to_int_count = 0\n",
    "\tfor col in df.select_dtypes(include=['object']).columns:\n",
    "\t\ttry:\n",
    "\t\t\t# Try converting to numeric\n",
    "\t\t\tconverted = pd.to_numeric(df[col], errors='coerce')\n",
    "\t\t\tif converted.notna().sum() / len(df) > 0.9:  # If 90%+ can be converted\n",
    "\t\t\t\tconverted_count = converted.notna().sum()\n",
    "\t\t\t\tlog(f\"Converting {col} from string to int ({converted_count} values converted)\")\n",
    "\t\t\t\tdf[col] = converted.fillna(0).astype('int64')\n",
    "\t\t\t\tstring_to_int_count += 1\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\t\n",
    "\tif string_to_int_count > 0:\n",
    "\t\tlog(f\"Total columns converted from string to int: {string_to_int_count}\")\n",
    "\t\n",
    "\t# Identify categorical columns for one-hot encoding\n",
    "\t# Look for columns with limited unique values (nominal categories)\n",
    "\tcategorical_cols = []\n",
    "\tfor col in df.columns:\n",
    "\t\tif df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
    "\t\t\tcategorical_cols.append(col)\n",
    "\t\telif df[col].dtype in ['int64', 'int32']:\n",
    "\t\t\t# Could be categorical if low cardinality\n",
    "\t\t\tunique_count = df[col].nunique()\n",
    "\t\t\tif unique_count <= 10 and unique_count < len(df) * 0.1:\n",
    "\t\t\t\t# Low cardinality, might be categorical\n",
    "\t\t\t\t# But we'll handle payment status separately\n",
    "\t\t\t\tpass\n",
    "\t\n",
    "\t# One-hot encode nominal categories (where order doesn't matter)\n",
    "\t# Common ones: SEX, EDUCATION, MARRIAGE\n",
    "\tnominal_cols = []\n",
    "\tfor col in categorical_cols:\n",
    "\t\tcol_lower = str(col).lower()\n",
    "\t\tif any(x in col_lower for x in ['sex', 'gender', 'education', 'marriage', 'marital']):\n",
    "\t\t\tnominal_cols.append(col)\n",
    "\t\n",
    "\t# Also check for other low-cardinality int columns that might be nominal\n",
    "\tfor col in df.select_dtypes(include=['int64', 'int32']).columns:\n",
    "\t\tcol_lower = str(col).lower()\n",
    "\t\tif col_lower in ['sex', 'education', 'marriage'] and df[col].nunique() <= 10:\n",
    "\t\t\tnominal_cols.append(col)\n",
    "\t\n",
    "\tlog(f\"\\nOne-hot encoding nominal categories: {nominal_cols}\")\n",
    "\tfor col in nominal_cols:\n",
    "\t\tif col in df.columns:\n",
    "\t\t\tdummies = pd.get_dummies(df[col], prefix=col, drop_first=True)\n",
    "\t\t\tdf = pd.concat([df, dummies], axis=1)\n",
    "\t\t\tdf = df.drop(columns=[col])\n",
    "\t\t\tlog(f\"  -> Encoded {col} into {len(dummies.columns)} binary columns\")\n",
    "\t\n",
    "\t# Ordinal encode payment status (where order matters)\n",
    "\t# Look for PAY_ columns or payment status columns\n",
    "\tpayment_cols = []\n",
    "\tfor col in df.columns:\n",
    "\t\tcol_lower = str(col).lower()\n",
    "\t\tif 'pay' in col_lower and ('status' in col_lower or col_lower.startswith('pay_')):\n",
    "\t\t\tpayment_cols.append(col)\n",
    "\t\n",
    "\tlog(f\"\\nPayment status columns (keeping as ordinal): {payment_cols}\")\n",
    "\t# Payment status is already numeric typically, but we'll ensure it's int\n",
    "\tfor col in payment_cols:\n",
    "\t\tif col in df.columns:\n",
    "\t\t\tdf[col] = df[col].astype('int64')\n",
    "\t\t\tlog(f\"  -> {col} kept as ordinal (int)\")\n",
    "\t\n",
    "\t# Int -> Category (where applicable - for memory efficiency)\n",
    "\t# Only for very low cardinality columns that aren't being used in calculations\n",
    "\tfor col in df.select_dtypes(include=['int64', 'int32']).columns:\n",
    "\t\tif col not in payment_cols and df[col].nunique() <= 5:\n",
    "\t\t\tcol_lower = str(col).lower()\n",
    "\t\t\t# Don't convert if it's a bill amount, payment amount, or limit\n",
    "\t\t\tif not any(x in col_lower for x in ['bill', 'pay_amt', 'limit', 'bal']):\n",
    "\t\t\t\tlog(f\"Converting {col} to category for memory efficiency\")\n",
    "\t\t\t\tdf[col] = df[col].astype('category')\n",
    "\t\n",
    "\t# Date(ish) -> Date-time\n",
    "\t# Look for date-like columns\n",
    "\tfor col in df.select_dtypes(include=['object']).columns:\n",
    "\t\ttry:\n",
    "\t\t\t# Try parsing as date\n",
    "\t\t\tparsed = pd.to_datetime(df[col], errors='coerce')\n",
    "\t\t\tif parsed.notna().sum() / len(df) > 0.5:  # If 50%+ can be parsed\n",
    "\t\t\t\tlog(f\"Converting {col} to datetime\")\n",
    "\t\t\t\tdf[col] = parsed\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\t\n",
    "\tlog(f\"\\nShape after type corrections: {df.shape}\")\n",
    "\t\n",
    "\t\"\"\"\n",
    "\tAnomaly detection\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tlog(\"REMOVING OUTLIERS\")\n",
    "\t\n",
    "\tinitial_rows = len(df)\n",
    "\t\n",
    "\t# Method 1: 2 Standard Deviations (2-SD)\n",
    "\tlog(\"Using 2-SD method:\")\n",
    "\tnumeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\toutliers_2sd = set()\n",
    "\t\n",
    "\tfor col in numeric_cols:\n",
    "\t\tz_scores = np.abs(zscore(df[col].dropna()))\n",
    "\t\toutlier_mask = z_scores > 2\n",
    "\t\toutlier_count = outlier_mask.sum()\n",
    "\t\tif outlier_count > 0:\n",
    "\t\t\toutlier_indices = df[col].index[outlier_mask]\n",
    "\t\t\toutliers_2sd.update(outlier_indices)\n",
    "\t\t\tlog(f\"  {col}: {outlier_count} outliers (|z| > 2)\")\n",
    "\t\n",
    "\t# Method 2: IQR (Interquartile Range)\n",
    "\tlog(\"Using IQR method:\")\n",
    "\toutliers_iqr = set()\n",
    "\t\n",
    "\tfor col in numeric_cols:\n",
    "\t\tQ1 = df[col].quantile(0.25)\n",
    "\t\tQ3 = df[col].quantile(0.75)\n",
    "\t\tIQR = Q3 - Q1\n",
    "\t\tlower_bound = Q1 - 1.5 * IQR\n",
    "\t\tupper_bound = Q3 + 1.5 * IQR\n",
    "\t\toutlier_mask = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "\t\toutlier_count = outlier_mask.sum()\n",
    "\t\tif outlier_count > 0:\n",
    "\t\t\toutlier_indices = df[col].index[outlier_mask]\n",
    "\t\t\toutliers_iqr.update(outlier_indices)\n",
    "\t\t\tlog(f\"  {col}: {outlier_count} outliers (outside IQR bounds)\")\n",
    "\t\n",
    "\t# Combine both methods - remove if flagged by either\n",
    "\tall_outliers = outliers_2sd.union(outliers_iqr)\n",
    "\tlog(f\"\\nTotal unique outlier rows: {len(all_outliers)}\")\n",
    "\t\n",
    "\t# For now, we'll use winsorization instead of removal to preserve data\n",
    "\t# Winsorize extreme values to 1st and 99th percentiles\n",
    "\tlog(\"\\nWinsorizing extreme values (1st and 99th percentiles):\")\n",
    "\ttotal_winsorized = 0\n",
    "\tfor col in numeric_cols:\n",
    "\t\t# Skip if it's a binary/categorical column\n",
    "\t\tif df[col].nunique() <= 2:\n",
    "\t\t\tcontinue\n",
    "\t\t\n",
    "\t\toriginal_values = df[col].copy()\n",
    "\t\toriginal_min = df[col].min()\n",
    "\t\toriginal_max = df[col].max()\n",
    "\t\t\n",
    "\t\t# Winsorize at 1st and 99th percentiles\n",
    "\t\twinsorized = winsorize(df[col].values, limits=[0.01, 0.01])\n",
    "\t\t# Convert masked array to regular array\n",
    "\t\tdf[col] = np.array(winsorized)\n",
    "\t\t\n",
    "\t\t# Count how many values were actually changed\n",
    "\t\tvalues_changed = (original_values != df[col]).sum()\n",
    "\t\tif values_changed > 0:\n",
    "\t\t\ttotal_winsorized += values_changed\n",
    "\t\t\tlog(f\"  {col}: {values_changed} values clipped (min: {original_min:.2f}->{df[col].min():.2f}, max: {original_max:.2f}->{df[col].max():.2f})\")\n",
    "\t\n",
    "\tlog(f\"\\nTotal values winsorized across all columns: {total_winsorized}\")\n",
    "\t\n",
    "\t# Group rare values into \"Other\" for categorical columns\n",
    "\tlog(\"\\nGrouping rare categorical values into 'Other':\")\n",
    "\tfor col in df.select_dtypes(include=['object', 'category']).columns:\n",
    "\t\tvalue_counts = df[col].value_counts()\n",
    "\t\t# If a value appears in less than 1% of rows, group it as \"Other\"\n",
    "\t\trare_threshold = len(df) * 0.01\n",
    "\t\trare_values = value_counts[value_counts < rare_threshold].index.tolist()\n",
    "\t\t\n",
    "\t\tif len(rare_values) > 0 and len(rare_values) < len(value_counts):\n",
    "\t\t\tlog(f\"  {col}: grouping {len(rare_values)} rare values into 'Other'\")\n",
    "\t\t\tdf[col] = df[col].replace(rare_values, 'Other')\n",
    "\t\n",
    "\tlog(f\"\\nShape after anomaly handling: {df.shape} (removed {initial_rows - len(df)} rows)\")\n",
    "\t\n",
    "\t\"\"\"\n",
    "\tQOL FEATURES (Quality of Life / Derived Features)\n",
    "\t\"\"\"\n",
    "\tlog(\"CREATING DERIVED FEATURES\")\n",
    "\t\n",
    "\t# Find bill amount columns (BILL_AMT1, BILL_AMT2, etc.) - bill_amt is the default column name for bill amounts\n",
    "\tbill_cols = [col for col in df.columns if 'bill_amt' in str(col).lower()]\n",
    "\t# Also check for PAY_AMT columns (payment amounts) - pay_amt is the default column name for payment amounts\n",
    "\tpay_amt_cols = [col for col in df.columns if 'pay_amt' in str(col).lower()]\n",
    "\t\n",
    "\tlog(f\"Found bill columns: {bill_cols}\")\n",
    "\tlog(f\"Found payment amount columns: {pay_amt_cols}\")\n",
    "\t\n",
    "\t# Total bills paid to date (sum of all payment amounts)\n",
    "\tif pay_amt_cols:\n",
    "\t\tdf['total_bills_paid_to_date'] = df[pay_amt_cols].sum(axis=1)\n",
    "\t\tlog(f\"Created: total_bills_paid_to_date\")\n",
    "\t\n",
    "\t# Average bill amount\n",
    "\tif bill_cols:\n",
    "\t\tdf['avg_bill'] = df[bill_cols].mean(axis=1)\n",
    "\t\tlog(f\"Created: avg_bill\")\n",
    "\t\n",
    "\t# Total in processing (current outstanding bills)\n",
    "\tif bill_cols:\n",
    "\t\tdf['current_outstanding'] = df[bill_cols].sum(axis=1)\n",
    "\t\tlog(f\"Created: current_outstanding\")\n",
    "\t\n",
    "\t# Amortised debt (rough estimate: bills - payments over time)\n",
    "\tif bill_cols and pay_amt_cols:\n",
    "\t\t# Sum of bills minus sum of payments\n",
    "\t\tdf['amortised_debt'] = df[bill_cols].sum(axis=1) - df[pay_amt_cols].sum(axis=1)\n",
    "\t\t# Can't have negative amortised debt in this context\n",
    "\t\tdf['amortised_debt'] = df['amortised_debt'].clip(lower=0)\n",
    "\t\tlog(f\"Created: amortised_debt\")\n",
    "\t\n",
    "\t# Temporal features - payment timing\n",
    "\t# Find payment status columns (PAY_0, PAY_2, etc. or PAY_1, PAY_2, etc.)\n",
    "\tpay_status_cols = [col for col in df.columns if 'pay' in str(col).lower() and col not in pay_amt_cols and 'status' not in str(col).lower()]\n",
    "\t# Filter to actual payment status columns (usually PAY_0, PAY_2, PAY_3, etc.)\n",
    "\tpay_status_cols = [col for col in pay_status_cols if any(x in col for x in ['PAY_', 'Pay_', 'pay_'])]\n",
    "\t\n",
    "\tif pay_status_cols:\n",
    "\t\t# How overdue on average (negative values = paid early, positive = overdue)\n",
    "\t\t# Payment status typically: -1 = paid duly, 0 = no consumption, 1+ = months overdue\n",
    "\t\tdf['avg_overdue_months'] = df[pay_status_cols].mean(axis=1)\n",
    "\t\tlog(f\"Create: avg_overdue_months\")\n",
    "\t\t\n",
    "\t\t# Max overdue months\n",
    "\t\tdf['max_overdue_months'] = df[pay_status_cols].max(axis=1)\n",
    "\t\tlog(f\"Created: max_overdue_months\")\n",
    "\t\t\n",
    "\t\t# Count of months with overdue payments\n",
    "\t\tdf['months_overdue_count'] = (df[pay_status_cols] > 0).sum(axis=1)\n",
    "\t\tlog(f\"Created: months_overdue_count\")\n",
    "\t\n",
    "\t# Credit utilisation\n",
    "\t# Look for limit and balance columns\n",
    "\tlimit_col = None\n",
    "\tbalance_col = None\n",
    "\t\n",
    "\tfor col in df.columns:\n",
    "\t\tcol_lower = str(col).lower()\n",
    "\t\tif 'limit' in col_lower and 'bal' in col_lower:\n",
    "\t\t\tlimit_col = col\n",
    "\t\tif ('balance' in col_lower or 'bal' in col_lower) and 'limit' not in col_lower:\n",
    "\t\t\tbalance_col = col\n",
    "\t\n",
    "\tif limit_col and balance_col:\n",
    "\t\t# Avoid division by zero\n",
    "\t\tdf['credit_utilisation'] = np.where(\n",
    "\t\t\tdf[limit_col] > 0,\n",
    "\t\t\tdf[balance_col] / df[limit_col],\n",
    "\t\t\t0\n",
    "\t\t)\n",
    "\t\t# Cap at 1.0 (100% utilisation)\n",
    "\t\tdf['credit_utilisation'] = df['credit_utilisation'].clip(upper=1.0)\n",
    "\t\tlog(f\"Created: credit_utilisation (using {limit_col} and {balance_col})\")\n",
    "\telif limit_col:\n",
    "\t\t# If we have limit but no current balance, use total bills as proxy\n",
    "\t\tif bill_cols:\n",
    "\t\t\tdf['credit_utilisation'] = np.where(\n",
    "\t\t\t\tdf[limit_col] > 0,\n",
    "\t\t\t\tdf[bill_cols].sum(axis=1) / df[limit_col],\n",
    "\t\t\t\t0\n",
    "\t\t\t)\n",
    "\t\t\tdf['credit_utilisation'] = df['credit_utilisation'].clip(upper=1.0)\n",
    "\t\t\tlog(f\"Created: credit_utilisation (using {limit_col} and bill amounts as proxy)\")\n",
    "\t\n",
    "\tlog(f\"\\nShaape after creating derived features: {df.shape}\")\n",
    "\t\n",
    "\t\"\"\"\n",
    "\tFinal summary\n",
    "\t\"\"\"\n",
    "\tlog(\"FINAL DATA SUMMARY\")\n",
    "\t\n",
    "\tlog(f\"\\nFinal shape: {df.shape}\")\n",
    "\tlog(f\"Final columns: {len(df.columns)}\")\n",
    "\tlog(f\"\\nColumn names:\")\n",
    "\tfor i, col in enumerate(df.columns, 1):\n",
    "\t\tlog(f\"  {i}. {col}\")\n",
    "\t\n",
    "\tlog(f\"\\nFinal dtypes:\")\n",
    "\tlog(df.dtypes.value_counts())\n",
    "\t\n",
    "\tlog(f\"\\nFinal missing values:\")\n",
    "\tfinal_missing = df.isna().sum()\n",
    "\tif final_missing.sum() > 0:\n",
    "\t\tlog(final_missing[final_missing > 0])\n",
    "\telse:\n",
    "\t\tlog(\"None\")\n",
    "\t\n",
    "\t# Ensure cleaned dataset is still large enough\n",
    "\tlog(f\"\\nDataset size validation:\")\n",
    "\tlog(f\"Minimum requirement: 2,500 rows - Current: {df.shape[0]} rows\")\n",
    "\tif df.shape[0] >= 2500:\n",
    "\t\tlog(\"Dataset size meets minimum requirement\")\n",
    "\telse:\n",
    "\t\tlog(\"WARNING: Dataset size below minimum requirement\")\n",
    "\t\traise ValueError(f\"Dataset too small: {df.shape[0]} rows (minimum: 2,500)\")\n",
    "\t\n",
    "\t# Check class balance if target column exists\n",
    "\ttarget_col = 'default_payment_next_month'\n",
    "\tif target_col in df.columns:\n",
    "\t\tclass_counts = df[target_col].value_counts()\n",
    "\t\tclass_balance = class_counts.min() / class_counts.max()\n",
    "\t\tlog(f\"\\nClass balance check:\")\n",
    "\t\tlog(f\"  Class distribution:\\n{class_counts}\")\n",
    "\t\tlog(f\"  Balance ratio: {class_balance:.3f}\")\n",
    "\t\tif class_balance < 0.25:  # Less than 25% means >75% in one class\n",
    "\t\t\tlog(f\"  WARNING: Class imbalance detected (>75% in majority class)\")\n",
    "\t\t\tlog(f\"  Consider using class_weight='balanced' or SMOTE\")\n",
    "\t\telse:\n",
    "\t\t\tlog(f\"  Class balance is acceptable\")\n",
    "\t\n",
    "\t# Separate features and target if splitting\n",
    "\tif split_data:\n",
    "\t\tif target_col not in df.columns:\n",
    "\t\t\traise ValueError(\"Cannot split data: target column 'default_payment_next_month' not found\")\n",
    "\t\t\n",
    "\t\tscaler = None  # Initialize scaler variable\n",
    "\t\tX = df.drop(columns=[target_col])\n",
    "\t\ty = df[target_col]\n",
    "\t\t\n",
    "\t\tlog(\"\\nTRAIN/TEST SPLIT\")\n",
    "\t\t\n",
    "\t\t# Stratified train/test split\n",
    "\t\tX_train, X_test, y_train, y_test = train_test_split(\n",
    "\t\t\tX, y, \n",
    "\t\t\ttest_size=test_size, \n",
    "\t\t\trandom_state=random_state,\n",
    "\t\t\tstratify=y  # Stratified split to maintain class distribution\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tlog(f\"Training set: {X_train.shape[0]} rows, {X_train.shape[1]} features\")\n",
    "\t\tlog(f\"Test set: {X_test.shape[0]} rows, {X_test.shape[1]} features\")\n",
    "\t\tlog(f\"Training class distribution:\\n{y_train.value_counts()}\")\n",
    "\t\tlog(f\"Test class distribution:\\n{y_test.value_counts()}\")\n",
    "\t\t\n",
    "\t\t# Apply SMOTE to training data if requested\n",
    "\t\tif apply_smote:\n",
    "\t\t\tlog(f\"\\nApplying SMOTE to training data...\")\n",
    "\t\t\ttry:\n",
    "\t\t\t\tsmote = SMOTE(random_state=random_state)\n",
    "\t\t\t\tX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\t\t\t\tlog(f\"Before SMOTE: {X_train.shape[0]} samples\")\n",
    "\t\t\t\tlog(f\"After SMOTE: {X_train_resampled.shape[0]} samples\")\n",
    "\t\t\t\tlog(f\"Resampled class distribution:\\n{pd.Series(y_train_resampled).value_counts()}\")\n",
    "\t\t\t\tX_train = pd.DataFrame(X_train_resampled, columns=X_train.columns, index=X_train.index[:len(X_train_resampled)])\n",
    "\t\t\t\ty_train = pd.Series(y_train_resampled, index=X_train.index)\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tlog(f\"WARNING: SMOTE failed: {e}\")\n",
    "\t\t\t\tlog(\"Continuing without SMOTE...\")\n",
    "\t\t\n",
    "\t\t# Apply scaling if requested\n",
    "\t\tif apply_scaling:\n",
    "\t\t\tlog(\"\\nAPPLYING SCALING\")\n",
    "\t\t\t\n",
    "\t\t\t# Use robust scaling if anomalies were detected (winsorization was applied)\n",
    "\t\t\t# Otherwise use standard scaling\n",
    "\t\t\tuse_robust = total_winsorized > 0\n",
    "\t\t\t\n",
    "\t\t\tif use_robust:\n",
    "\t\t\t\tlog(\"Using RobustScaler (anomalies detected in data)\")\n",
    "\t\t\t\tscaler = RobustScaler()\n",
    "\t\t\telse:\n",
    "\t\t\t\tlog(\"Using StandardScaler\")\n",
    "\t\t\t\tscaler = StandardScaler()\n",
    "\t\t\t\n",
    "\t\t\t# Fit on training data, transform both train and test\n",
    "\t\t\tX_train_scaled = scaler.fit_transform(X_train)\n",
    "\t\t\tX_test_scaled = scaler.transform(X_test)\n",
    "\t\t\t\n",
    "\t\t\t# Convert back to DataFrame with original column names\n",
    "\t\t\tX_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "\t\t\tX_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\t\t\t\n",
    "\t\t\tlog(\"Scaling applied to training and test sets\")\n",
    "\t\t\n",
    "\t\tlog(\"\\nFINAL SUMMARY\")\n",
    "\t\tlog(f\"Training set shape: {X_train.shape}\")\n",
    "\t\tlog(f\"Test set shape: {X_test.shape}\")\n",
    "\t\tlog(f\"\\nDataset ready for modeling!\")\n",
    "\t\t\n",
    "\t\t# Always return scaler when splitting (None if scaling wasn't applied)\n",
    "\t\treturn X_train, X_test, y_train, y_test, scaler\n",
    "\t\n",
    "\t# Apply scaling to entire dataset if requested (and not splitting)\n",
    "\tif apply_scaling:\n",
    "\t\tlog(\"\\nAPPLYING SCALING\")\n",
    "\t\t\n",
    "\t\t# Use robust scaling if anomalies were detected (winsorization was applied)\n",
    "\t\tuse_robust = total_winsorized > 0\n",
    "\t\t\n",
    "\t\tif use_robust:\n",
    "\t\t\tlog(\"Using RobustScaler (anomalies detected in data)\")\n",
    "\t\t\tscaler = RobustScaler()\n",
    "\t\telse:\n",
    "\t\t\tlog(\"Using StandardScaler\")\n",
    "\t\t\tscaler = StandardScaler()\n",
    "\t\t\n",
    "\t\t# Separate target if it exists\n",
    "\t\tif target_col in df.columns:\n",
    "\t\t\tX = df.drop(columns=[target_col])\n",
    "\t\t\ty = df[target_col]\n",
    "\t\t\t\n",
    "\t\t\t# Scale only features\n",
    "\t\t\tX_scaled = scaler.fit_transform(X)\n",
    "\t\t\tX_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
    "\t\t\t\n",
    "\t\t\t# Recombine\n",
    "\t\t\tdf = pd.concat([X_scaled, y], axis=1)\n",
    "\t\telse:\n",
    "\t\t\t# Scale all numeric columns\n",
    "\t\t\tnumeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\t\t\tdf_scaled = scaler.fit_transform(df[numeric_cols])\n",
    "\t\t\tdf[numeric_cols] = df_scaled\n",
    "\t\t\n",
    "\t\tlog(\"Scaling applied to dataset\")\n",
    "\t\n",
    "\tlog(\"\\nFINAL SUMMARY\")\n",
    "\tlog(f\"Final shape: {df.shape}\")\n",
    "\tlog(f\"\\nDataset ready for modeling!\")\n",
    "\t\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6fa000",
   "metadata": {},
   "source": [
    "## Model Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22e90ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report, confusion_matrix, accuracy_score, average_precision_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def check_class_imbalance(y):\n",
    "\t\"\"\"\n",
    "\tCheck if class imbalance is significant (>60:40 ratio).\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tbool: True if imbalance is significant\n",
    "\t\"\"\"\n",
    "\tclass_counts = y.value_counts()\n",
    "\tratio = class_counts.min() / class_counts.max()\n",
    "\treturn ratio < 0.4\n",
    "\n",
    "def get_logistic_regression(class_imbalance=False, random_state=42):\n",
    "\t\"\"\"\n",
    "\tCreate Logistic Regression model with L2 penalty.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tclass_imbalance: If True, use class_weight='balanced'\n",
    "\t\trandom_state: Random seed\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tLogisticRegression model\n",
    "\t\"\"\"\n",
    "\tif class_imbalance:\n",
    "\t\treturn LogisticRegression(\n",
    "\t\t\tpenalty='l2',\n",
    "\t\t\tsolver='liblinear',\n",
    "\t\t\tclass_weight='balanced',\n",
    "\t\t\trandom_state=random_state,\n",
    "\t\t\tmax_iter=1000\n",
    "\t\t)\n",
    "\telse:\n",
    "\t\treturn LogisticRegression(\n",
    "\t\t\tpenalty='l2',\n",
    "\t\t\tsolver='saga',\n",
    "\t\t\trandom_state=random_state,\n",
    "\t\t\tmax_iter=1000\n",
    "\t\t)\n",
    "\n",
    "def get_random_forest(random_state=42):\n",
    "\t\"\"\"\n",
    "\tCreate Random Forest classifier as baseline.\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tRandomForestClassifier model\n",
    "\t\"\"\"\n",
    "\treturn RandomForestClassifier(\n",
    "\t\tn_estimators=100,\n",
    "\t\trandom_state=random_state,\n",
    "\t\tn_jobs=-1\n",
    "\t)\n",
    "\n",
    "def get_gradient_boosting(random_state=42):\n",
    "\t\"\"\"\n",
    "\tCreate Gradient Boosting Tree classifier.\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tGradientBoostingClassifier model\n",
    "\t\"\"\"\n",
    "\treturn GradientBoostingClassifier(\n",
    "\t\trandom_state=random_state,\n",
    "\t\tvalidation_fraction=0.1,\n",
    "\t\tn_iter_no_change=5\n",
    "\t)\n",
    "\n",
    "def get_neural_network(random_state=42):\n",
    "\t\"\"\"\n",
    "\tCreate simple Neural Network (MLP) for comparison.\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tMLPClassifier model\n",
    "\t\"\"\"\n",
    "\treturn MLPClassifier(\n",
    "\t\thidden_layer_sizes=(100, 50),\n",
    "\t\tactivation='relu',\n",
    "\t\tsolver='adam',\n",
    "\t\talpha=0.0001,\n",
    "\t\tbatch_size='auto',\n",
    "\t\tlearning_rate='constant',\n",
    "\t\tlearning_rate_init=0.001,\n",
    "\t\tmax_iter=500,\n",
    "\t\trandom_state=random_state,\n",
    "\t\tearly_stopping=True,\n",
    "\t\tvalidation_fraction=0.1\n",
    "\t)\n",
    "\n",
    "def tune_model_randomized(model, param_distributions, X_train, y_train, \n",
    "\t\t\t\t\t\t  n_iter=50, cv_fold=None, scoring='roc_auc', random_state=42, verbose=0):\n",
    "\t\"\"\"\n",
    "\tUse RandomizedSearchCV for broad hyperparameter search.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tmodel: Base model to tune\n",
    "\t\tparam_distributions: Dictionary of parameter distributions\n",
    "\t\tX_train: Training features\n",
    "\t\ty_train: Training target\n",
    "\t\tn_iter: Number of iterations\n",
    "\t\tcv_fold: Pre-defined CV fold object (for fairness across models)\n",
    "\t\tscoring: Scoring metric\n",
    "\t\trandom_state: Random seed\n",
    "\t\tverbose: Verbosity level\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tBest model from RandomizedSearchCV\n",
    "\t\"\"\"\n",
    "\tif cv_fold is None:\n",
    "\t\tcv_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\t\n",
    "\trandom_search = RandomizedSearchCV(\n",
    "\t\testimator=model,\n",
    "\t\tparam_distributions=param_distributions,\n",
    "\t\tn_iter=n_iter,\n",
    "\t\tcv=cv_fold,\n",
    "\t\tscoring=scoring,\n",
    "\t\trandom_state=random_state,\n",
    "\t\tn_jobs=-1,\n",
    "\t\tverbose=verbose\n",
    "\t)\n",
    "\t\n",
    "\trandom_search.fit(X_train, y_train)\n",
    "\treturn random_search.best_estimator_, random_search.best_params_, random_search.best_score_\n",
    "\n",
    "def tune_model_grid(model, param_grid, X_train, y_train, \n",
    "\t\t\t\t\tcv_fold=None, scoring='roc_auc', verbose=0):\n",
    "\t\"\"\"\n",
    "\tUse GridSearchCV to refine hyperparameter search in target region.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tmodel: Base model to tune\n",
    "\t\tparam_grid: Dictionary of parameter grid\n",
    "\t\tX_train: Training features\n",
    "\t\ty_train: Training target\n",
    "\t\tcv_fold: Pre-defined CV fold object (for fairness across models)\n",
    "\t\tscoring: Scoring metric\n",
    "\t\tverbose: Verbosity level\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tBest model from GridSearchCV\n",
    "\t\"\"\"\n",
    "\tif cv_fold is None:\n",
    "\t\tcv_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\t\n",
    "\tgrid_search = GridSearchCV(\n",
    "\t\testimator=model,\n",
    "\t\tparam_grid=param_grid,\n",
    "\t\tcv=cv_fold,\n",
    "\t\tscoring=scoring,\n",
    "\t\tn_jobs=-1,\n",
    "\t\tverbose=verbose\n",
    "\t)\n",
    "\t\n",
    "\tgrid_search.fit(X_train, y_train)\n",
    "\treturn grid_search.best_estimator_, grid_search.best_params_, grid_search.best_score_\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name=\"Model\", verbose=True):  # type: ignore\n",
    "\t\"\"\"\n",
    "\tEvaluate model using ROC-AUC and F1 score.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tmodel: Trained model\n",
    "\t\tX_train: Training features\n",
    "\t\ty_train: Training target\n",
    "\t\tX_test: Test features\n",
    "\t\ty_test: Test target\n",
    "\t\tmodel_name: Name for logging\n",
    "\t\tverbose: If True, print results\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tDictionary with evaluation metrics\n",
    "\t\"\"\"\n",
    "\t# Predictions\n",
    "\ty_train_pred = model.predict(X_train)\n",
    "\ty_test_pred = model.predict(X_test)\n",
    "\t\n",
    "\t# Probabilities for ROC-AUC\n",
    "\ty_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "\ty_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\t\n",
    "\t# Calculate metrics\n",
    "\ttrain_roc_auc = roc_auc_score(y_train, y_train_proba)\n",
    "\ttest_roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\ttrain_f1 = f1_score(y_train, y_train_pred)\n",
    "\ttest_f1 = f1_score(y_test, y_test_pred)\n",
    "\t\n",
    "\tresults = {\n",
    "\t\t'train_roc_auc': train_roc_auc,\n",
    "\t\t'test_roc_auc': test_roc_auc,\n",
    "\t\t'train_f1': train_f1,\n",
    "\t\t'test_f1': test_f1,\n",
    "\t\t'confusion_matrix': confusion_matrix(y_test, y_test_pred),\n",
    "\t\t'classification_report': classification_report(y_test, y_test_pred)\n",
    "\t}\n",
    "\t\n",
    "\tif verbose:\n",
    "\t\tprint(f\"\\n{model_name} Evaluation:\")\n",
    "\t\tprint(f\"Train ROC-AUC: {train_roc_auc:.4f}\")\n",
    "\t\tprint(f\"Test ROC-AUC: {test_roc_auc:.4f}\")\n",
    "\t\tprint(f\"Train F1: {train_f1:.4f}\")\n",
    "\t\tprint(f\"Test F1: {test_f1:.4f}\")\n",
    "\t\tprint(f\"\\nConfusion Matrix:\\n{results['confusion_matrix']}\")\n",
    "\t\tprint(f\"\\nClassification Report:\\n{results['classification_report']}\")\n",
    "\t\n",
    "\treturn results\n",
    "\n",
    "def get_hyperparameter_grids():\n",
    "\t\"\"\"\n",
    "\tDefine hyperparameter grids for each model.\n",
    "\t\n",
    "    # Parameter ranges based on scikit-learn docs defaults and common practice from Hastie et al. (2009)\n",
    "\t# Expanded ranges for randomized search, narrower grids for refinement\n",
    "\n",
    "\tReturns:\n",
    "\t\tDictionary of parameter distributions and grids for each model\n",
    "\t\"\"\"\n",
    "\tgrids = {\n",
    "\t\t'logistic_regression': {\n",
    "\t\t\t'randomized': {\n",
    "\t\t\t\t'C': np.logspace(-4, 4, 20),\n",
    "\t\t\t\t'solver': ['liblinear', 'saga'],\n",
    "\t\t\t\t'max_iter': [500, 1000, 2000]\n",
    "\t\t\t},\n",
    "\t\t\t'grid': {\n",
    "\t\t\t\t'C': np.logspace(-2, 2, 10),\n",
    "\t\t\t\t'solver': ['liblinear', 'saga']\n",
    "\t\t\t}\n",
    "\t\t},\n",
    "\t\t'random_forest': {\n",
    "\t\t\t'randomized': {\n",
    "\t\t\t\t'n_estimators': [50, 100, 200, 300],\n",
    "\t\t\t\t'max_depth': [None, 10, 20, 30],\n",
    "\t\t\t\t'min_samples_split': [2, 5, 10],\n",
    "\t\t\t\t'min_samples_leaf': [1, 2, 4],\n",
    "\t\t\t\t'max_features': ['sqrt', 'log2', None]\n",
    "\t\t\t},\n",
    "\t\t\t'grid': {\n",
    "\t\t\t\t'n_estimators': [100, 200],\n",
    "\t\t\t\t'max_depth': [10, 20, None],\n",
    "\t\t\t\t'min_samples_split': [2, 5],\n",
    "\t\t\t\t'max_features': ['sqrt', 'log2']\n",
    "\t\t\t}\n",
    "\t\t},\n",
    "\t\t'gradient_boosting': {\n",
    "\t\t\t'randomized': {\n",
    "\t\t\t\t'n_estimators': [50, 100, 200],\n",
    "\t\t\t\t'learning_rate': [0.01, 0.1, 0.2],\n",
    "\t\t\t\t'max_depth': [3, 5, 7],\n",
    "\t\t\t\t'min_samples_split': [2, 5],\n",
    "\t\t\t\t'min_samples_leaf': [1, 2],\n",
    "\t\t\t\t'subsample': [0.8, 0.9, 1.0]\n",
    "\t\t\t},\n",
    "\t\t\t'grid': {\n",
    "\t\t\t\t'n_estimators': [100, 200],\n",
    "\t\t\t\t'learning_rate': [0.05, 0.1],\n",
    "\t\t\t\t'max_depth': [3, 5],\n",
    "\t\t\t\t'subsample': [0.8, 0.9]\n",
    "\t\t\t}\n",
    "\t\t},\n",
    "\t\t'neural_network': {\n",
    "\t\t\t'randomized': {\n",
    "\t\t\t\t'hidden_layer_sizes': [(50,), (100,), (100, 50), (150, 100)],\n",
    "\t\t\t\t'alpha': [0.0001, 0.001, 0.01],\n",
    "\t\t\t\t'learning_rate_init': [0.001, 0.01],\n",
    "\t\t\t\t'max_iter': [300, 500]\n",
    "\t\t\t},\n",
    "\t\t\t'grid': {\n",
    "\t\t\t\t'hidden_layer_sizes': [(100,), (100, 50)],\n",
    "\t\t\t\t'alpha': [0.0001, 0.001],\n",
    "\t\t\t\t'learning_rate_init': [0.001, 0.01]\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "\treturn grids\n",
    "\n",
    "def train_and_tune_models(X_train, y_train, X_test, y_test,   # type: ignore\n",
    "\t\t\t\t\t\t  use_randomized=True, use_grid=True, \n",
    "\t\t\t\t\t\t  n_iter_randomized=50, cv=5, random_state=42, verbose=True):\n",
    "\t\"\"\"\n",
    "\tTrain and tune all models using RandomizedSearchCV and GridSearchCV.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tX_train: Training features\n",
    "\t\ty_train: Training target\n",
    "\t\tX_test: Test features\n",
    "\t\ty_test: Test target\n",
    "\t\tuse_randomized: If True, use RandomizedSearchCV first\n",
    "\t\tuse_grid: If True, refine with GridSearchCV\n",
    "\t\tn_iter_randomized: Number of iterations for RandomizedSearchCV\n",
    "\t\tcv: Number of CV folds\n",
    "\t\trandom_state: Random seed\n",
    "\t\tverbose: If True, print progress\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tDictionary of trained models and their results\n",
    "\t\"\"\"\n",
    "\tmodels = {}\n",
    "\tresults = {}\n",
    "\tgrids = get_hyperparameter_grids()\n",
    "\ttotal_start_time = time.time()\n",
    "\t\n",
    "\tcv_fold = StratifiedKFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
    "\t\n",
    "\tclass_imbalance = check_class_imbalance(y_train)\n",
    "\tif verbose:\n",
    "\t\tprint(f\"Class imbalance detected: {class_imbalance}\")\n",
    "\t\n",
    "\tmodel_start_time = time.time()\n",
    "\tif verbose:\n",
    "\t\tprint(\"\\nTraining Logistic Regression...\")\n",
    "\tlr = get_logistic_regression(class_imbalance=class_imbalance, random_state=random_state)\n",
    "\t\n",
    "\tif use_randomized:\n",
    "\t\tlr_best, lr_params, lr_score = tune_model_randomized(\n",
    "\t\t\tlr, grids['logistic_regression']['randomized'],\n",
    "\t\t\tX_train, y_train, n_iter=n_iter_randomized, cv_fold=cv_fold, random_state=random_state, verbose=0\n",
    "\t\t)\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(f\"RandomizedSearchCV best score: {lr_score:.4f}\")\n",
    "\t\t\tprint(f\"Best params: {lr_params}\")\n",
    "\t\t\n",
    "\t\tif use_grid:\n",
    "\t\t\t# Refine with grid search around best params\n",
    "\t\t\tgrid_params = grids['logistic_regression']['grid'].copy()\n",
    "\t\t\tif 'C' in lr_params:\n",
    "\t\t\t\tbest_c = lr_params['C']\n",
    "\t\t\t\t# Narrow C range around best value\n",
    "\t\t\t\tgrid_params['C'] = np.logspace(np.log10(best_c * 0.5), np.log10(best_c * 2), 5)\n",
    "\t\t\t\n",
    "\t\t\tlr_best, lr_params, lr_score = tune_model_grid(\n",
    "\t\t\t\tlr_best, grid_params, X_train, y_train, cv_fold=cv_fold, verbose=0\n",
    "\t\t\t)\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(f\"GridSearchCV best score: {lr_score:.4f}\")\n",
    "\t\t\t\tprint(f\"Refined params: {lr_params}\")\n",
    "\telse:\n",
    "\t\tlr_best = lr\n",
    "\t\tlr_best.fit(X_train, y_train)\n",
    "\t\n",
    "\tmodels['logistic_regression'] = lr_best\n",
    "\tresults['logistic_regression'] = evaluate_model(  # type: ignore\n",
    "\t\tlr_best, X_train, y_train, X_test, y_test, \"Logistic Regression\", verbose=verbose  # type: ignore\n",
    "\t)\n",
    "\tmodel_time = time.time() - model_start_time\n",
    "\taccuracy = accuracy_score(y_test, lr_best.predict(X_test))\n",
    "\tprint(f\"Logistic Regression finished, training time: {model_time:.2f}s, accuracy: {accuracy:.4f}\")\n",
    "\t\n",
    "\tmodel_start_time = time.time()\n",
    "\tif verbose:\n",
    "\t\tprint(\"\\nTraining Random Forest...\")\n",
    "\trf = get_random_forest(random_state=random_state)\n",
    "\t\n",
    "\tif use_randomized:\n",
    "\t\trf_best, rf_params, rf_score = tune_model_randomized(\n",
    "\t\t\trf, grids['random_forest']['randomized'],\n",
    "\t\t\tX_train, y_train, n_iter=n_iter_randomized, cv_fold=cv_fold, random_state=random_state, verbose=0\n",
    "\t\t)\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(f\"RandomizedSearchCV best score: {rf_score:.4f}\")\n",
    "\t\t\tprint(f\"Best params: {rf_params}\")\n",
    "\t\t\n",
    "\t\tif use_grid:\n",
    "\t\t\trf_best, rf_params, rf_score = tune_model_grid(\n",
    "\t\t\t\trf_best, grids['random_forest']['grid'], X_train, y_train, cv_fold=cv_fold, verbose=0\n",
    "\t\t\t)\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(f\"GridSearchCV best score: {rf_score:.4f}\")\n",
    "\t\t\t\tprint(f\"Refined params: {rf_params}\")\n",
    "\telse:\n",
    "\t\trf_best = rf\n",
    "\t\trf_best.fit(X_train, y_train)\n",
    "\t\n",
    "\tmodels['random_forest'] = rf_best\n",
    "\tresults['random_forest'] = evaluate_model(  # type: ignore\n",
    "\t\trf_best, X_train, y_train, X_test, y_test, \"Random Forest\", verbose=verbose  # type: ignore\n",
    "\t)\n",
    "\tmodel_time = time.time() - model_start_time\n",
    "\taccuracy = accuracy_score(y_test, rf_best.predict(X_test))\n",
    "\tprint(f\"Random Forest finished, training time: {model_time:.2f}s, accuracy: {accuracy:.4f}\")\n",
    "\t\n",
    "\tmodel_start_time = time.time()\n",
    "\tif verbose:\n",
    "\t\tprint(\"\\nTraining Gradient Boosting...\")\n",
    "\tgb = get_gradient_boosting(random_state=random_state)\n",
    "\t\n",
    "\tif use_randomized:\n",
    "\t\tgb_best, gb_params, gb_score = tune_model_randomized(\n",
    "\t\t\tgb, grids['gradient_boosting']['randomized'],\n",
    "\t\t\tX_train, y_train, n_iter=n_iter_randomized, cv_fold=cv_fold, random_state=random_state, verbose=0\n",
    "\t\t)\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(f\"RandomizedSearchCV best score: {gb_score:.4f}\")\n",
    "\t\t\tprint(f\"Best params: {gb_params}\")\n",
    "\t\t\n",
    "\t\tif use_grid:\n",
    "\t\t\tgb_best, gb_params, gb_score = tune_model_grid(\n",
    "\t\t\t\tgb_best, grids['gradient_boosting']['grid'], X_train, y_train, cv_fold=cv_fold, verbose=0\n",
    "\t\t\t)\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(f\"GridSearchCV best score: {gb_score:.4f}\")\n",
    "\t\t\t\tprint(f\"Refined params: {gb_params}\")\n",
    "\telse:\n",
    "\t\tgb_best = gb\n",
    "\t\tgb_best.fit(X_train, y_train)\n",
    "\t\n",
    "\tmodels['gradient_boosting'] = gb_best\n",
    "\tresults['gradient_boosting'] = evaluate_model(  # type: ignore\n",
    "\t\tgb_best, X_train, y_train, X_test, y_test, \"Gradient Boosting\", verbose=verbose  # type: ignore\n",
    "\t)\n",
    "\tmodel_time = time.time() - model_start_time\n",
    "\taccuracy = accuracy_score(y_test, gb_best.predict(X_test))\n",
    "\tprint(f\"Gradient Boosting finished, training time: {model_time:.2f}s, accuracy: {accuracy:.4f}\")\n",
    "\t\n",
    "\tmodel_start_time = time.time()\n",
    "\tif verbose:\n",
    "\t\tprint(\"\\nTraining Neural Network...\")\n",
    "\tnn = get_neural_network(random_state=random_state)\n",
    "\t\n",
    "\tif use_randomized:\n",
    "\t\tnn_best, nn_params, nn_score = tune_model_randomized(\n",
    "\t\t\tnn, grids['neural_network']['randomized'],\n",
    "\t\t\tX_train, y_train, n_iter=n_iter_randomized, cv_fold=cv_fold, random_state=random_state, verbose=0\n",
    "\t\t)\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(f\"RandomizedSearchCV best score: {nn_score:.4f}\")\n",
    "\t\t\tprint(f\"Best params: {nn_params}\")\n",
    "\t\t\n",
    "\t\tif use_grid:\n",
    "\t\t\tnn_best, nn_params, nn_score = tune_model_grid(\n",
    "\t\t\t\tnn_best, grids['neural_network']['grid'], X_train, y_train, cv_fold=cv_fold, verbose=0\n",
    "\t\t\t)\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(f\"GridSearchCV best score: {nn_score:.4f}\")\n",
    "\t\t\t\tprint(f\"Refined params: {nn_params}\")\n",
    "\telse:\n",
    "\t\tnn_best = nn\n",
    "\t\tnn_best.fit(X_train, y_train)\n",
    "\t\n",
    "\tmodels['neural_network'] = nn_best\n",
    "\tresults['neural_network'] = evaluate_model(  # type: ignore\n",
    "\t\tnn_best, X_train, y_train, X_test, y_test, \"Neural Network\", verbose=verbose  # type: ignore\n",
    "\t)\n",
    "\tmodel_time = time.time() - model_start_time\n",
    "\taccuracy = accuracy_score(y_test, nn_best.predict(X_test))\n",
    "\tprint(f\"Neural Network finished, training time: {model_time:.2f}s, accuracy: {accuracy:.4f}\")\n",
    "\t\n",
    "\ttotal_time = time.time() - total_start_time\n",
    "\t\n",
    "\tbest_model_name = None\n",
    "\tbest_accuracy = 0\n",
    "\tfor model_name, model in models.items():\n",
    "\t\tmodel_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "\t\tif model_accuracy > best_accuracy:\n",
    "\t\t\tbest_accuracy = model_accuracy\n",
    "\t\t\tbest_model_name = model_name\n",
    "\t\n",
    "\tmodel_name_display = {\n",
    "\t\t'logistic_regression': 'Logistic Regression',\n",
    "\t\t'random_forest': 'Random Forest',\n",
    "\t\t'gradient_boosting': 'Gradient Boosting',\n",
    "\t\t'neural_network': 'Neural Network'\n",
    "\t}\n",
    "\t\n",
    "\tprint(f\"\\nTotal training time: {total_time:.2f}s, most accurate: {model_name_display.get(best_model_name, best_model_name)} ({best_accuracy:.4f})\")\n",
    "\t\n",
    "\treturn models, results\n",
    "\n",
    "def create_stacked_model(models_dict, X_train, y_train, random_state=42, calibrate=False):  # type: ignore\n",
    "\t\"\"\"\n",
    "\tCreate stacked ensemble model using Random Forest + Gradient Boosting + Logistic Regression.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tmodels_dict: Dictionary containing trained models\n",
    "\t\tX_train: Training features\n",
    "\t\ty_train: Training target\n",
    "\t\trandom_state: Random seed\n",
    "\t\tcalibrate: If True, calibrate models for reliable probability outputs\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tStacked model (VotingClassifier)\n",
    "\t\"\"\"\n",
    "\t# Get base models\n",
    "\trf = models_dict.get('random_forest')\n",
    "\tgb = models_dict.get('gradient_boosting')\n",
    "\tlr = models_dict.get('logistic_regression')\n",
    "\t\n",
    "\tif rf is None or gb is None or lr is None:\n",
    "\t\traise ValueError(\"Need random_forest, gradient_boosting, and logistic_regression models\")\n",
    "\t\n",
    "\tif calibrate:\n",
    "\t\trf_calibrated = CalibratedClassifierCV(rf, method='isotonic', cv=3)\n",
    "\t\tgb_calibrated = CalibratedClassifierCV(gb, method='isotonic', cv=3)\n",
    "\t\tlr_calibrated = CalibratedClassifierCV(lr, method='isotonic', cv=3)\n",
    "\t\t\n",
    "\t\trf_calibrated.fit(X_train, y_train)\n",
    "\t\tgb_calibrated.fit(X_train, y_train)\n",
    "\t\tlr_calibrated.fit(X_train, y_train)\n",
    "\t\t\n",
    "\t\testimators = [\n",
    "\t\t\t('rf', rf_calibrated),\n",
    "\t\t\t('gb', gb_calibrated),\n",
    "\t\t\t('lr', lr_calibrated)\n",
    "\t\t]\n",
    "\telse:\n",
    "\t\testimators = [\n",
    "\t\t\t('rf', rf),\n",
    "\t\t\t('gb', gb),\n",
    "\t\t\t('lr', lr)\n",
    "\t\t]\n",
    "\t\n",
    "\t# Create voting classifier (soft voting for probabilities)\n",
    "\tstacked_model = VotingClassifier(\n",
    "\t\testimators=estimators,\n",
    "\t\tvoting='soft',\n",
    "\t\tweights=None\n",
    "\t)\n",
    "\t\n",
    "\tstacked_model.fit(X_train, y_train)\n",
    "\treturn stacked_model\n",
    "\n",
    "def get_feature_importance(model, feature_names, method='permutation', X_test=None, y_test=None):\n",
    "\t\"\"\"\n",
    "\tGet feature importance using different methods.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tmodel: Trained model\n",
    "\t\tfeature_names: List of feature names\n",
    "\t\tmethod: 'permutation', 'l1', or 'tree' (for tree-based models)\n",
    "\t\tX_test: Test features (needed for permutation importance)\n",
    "\t\ty_test: Test target (needed for permutation importance)\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tDataFrame with feature importances\n",
    "\t\"\"\"\n",
    "\tfrom sklearn.inspection import permutation_importance\n",
    "\t\n",
    "\tif method == 'permutation' and X_test is not None and y_test is not None:\n",
    "\t\tperm_importance = permutation_importance(\n",
    "\t\t\tmodel, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1\n",
    "\t\t)\n",
    "\t\timportances = perm_importance.importances_mean\n",
    "\t\tstd = perm_importance.importances_std\n",
    "\t\t\n",
    "\t\timportance_df = pd.DataFrame({\n",
    "\t\t\t'feature': feature_names,\n",
    "\t\t\t'importance': importances,\n",
    "\t\t\t'std': std\n",
    "\t\t}).sort_values('importance', ascending=False)\n",
    "\t\t\n",
    "\telif method == 'l1' and hasattr(model, 'coef_'):\n",
    "\t\t# L1 importance for linear models\n",
    "\t\tcoef = np.abs(model.coef_[0])\n",
    "\t\timportance_df = pd.DataFrame({\n",
    "\t\t\t'feature': feature_names,\n",
    "\t\t\t'importance': coef\n",
    "\t\t}).sort_values('importance', ascending=False)\n",
    "\t\t\n",
    "\telif method == 'tree' and hasattr(model, 'feature_importances_'):\n",
    "\t\t# Tree-based feature importance\n",
    "\t\timportance_df = pd.DataFrame({\n",
    "\t\t\t'feature': feature_names,\n",
    "\t\t\t'importance': model.feature_importances_\n",
    "\t\t}).sort_values('importance', ascending=False)\n",
    "\t\t\n",
    "\telse:\n",
    "\t\traise ValueError(f\"Method {method} not available for this model type\")\n",
    "\t\n",
    "\treturn importance_df\n",
    "\n",
    "def drop_negligible_features(X_train, X_test, feature_importance_df, threshold=0.01):\n",
    "\t\"\"\"\n",
    "\tDrop features with importance below threshold to reduce overfitting.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tX_train: Training features\n",
    "\t\tX_test: Test features\n",
    "\t\tfeature_importance_df: DataFrame with feature importances\n",
    "\t\tthreshold: Minimum importance threshold (relative to max)\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tFiltered X_train, X_test, and list of dropped features\n",
    "\t\"\"\"\n",
    "\tmax_importance = feature_importance_df['importance'].max()\n",
    "\tthreshold_value = max_importance * threshold\n",
    "\t\n",
    "\timportant_features = feature_importance_df[\n",
    "\t\tfeature_importance_df['importance'] >= threshold_value\n",
    "\t]['feature'].tolist()\n",
    "\t\n",
    "\tdropped_features = [f for f in X_train.columns if f not in important_features]\n",
    "\t\n",
    "\tX_train_filtered = X_train[important_features]\n",
    "\tX_test_filtered = X_test[important_features]\n",
    "\t\n",
    "\treturn X_train_filtered, X_test_filtered, dropped_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6982b5b",
   "metadata": {},
   "source": [
    "## Analysis and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bae99392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from scipy import stats\n",
    "from sklearn.metrics import (\n",
    "\troc_auc_score, precision_score, recall_score, f1_score,\n",
    "\tconfusion_matrix, average_precision_score, brier_score_loss\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.base import clone\n",
    "\n",
    "def comprehensive_evaluation(model, X_test, y_test, model_name=\"Model\", \n",
    "\t\t\t\t\t\t\tcost_false_positive=100, cost_false_negative=5000, verbose=True):\n",
    "\t\"\"\"\n",
    "\tComprehensive evaluation of a model with all relevant metrics.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tmodel: Trained model\n",
    "\t\tX_test: Test features\n",
    "\t\ty_test: Test target\n",
    "\t\tmodel_name: Name of the model for display\n",
    "\t\tcost_false_positive: Business cost of false positive (incorrectly predicting default)\n",
    "\t\tcost_false_negative: Business cost of false negative (missing a default)\n",
    "\t\tverbose: If True, print all metrics\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tDictionary containing all evaluation metrics\n",
    "\t\"\"\"\n",
    "\ty_pred = model.predict(X_test)\n",
    "\ty_proba = model.predict_proba(X_test)[:, 1]\n",
    "\t\n",
    "\troc_auc = roc_auc_score(y_test, y_proba)\n",
    "\tprecision = precision_score(y_test, y_pred)\n",
    "\trecall = recall_score(y_test, y_pred)\n",
    "\tf1 = f1_score(y_test, y_pred)\n",
    "\tpr_auc = average_precision_score(y_test, y_proba)\n",
    "\tbrier_score = brier_score_loss(y_test, y_proba)\n",
    "\tcm = confusion_matrix(y_test, y_pred)\n",
    "\t\n",
    "\ttn, fp, fn, tp = cm.ravel()\n",
    "\t\n",
    "\ttotal_cost = (fp * cost_false_positive) + (fn * cost_false_negative)\n",
    "\tcost_per_prediction = total_cost / len(y_test)\n",
    "\t\n",
    "\tresults = {\n",
    "\t\t'roc_auc': roc_auc,\n",
    "\t\t'precision': precision,\n",
    "\t\t'recall': recall,\n",
    "\t\t'f1': f1,\n",
    "\t\t'pr_auc': pr_auc,\n",
    "\t\t'brier_score': brier_score,\n",
    "\t\t'confusion_matrix': cm,\n",
    "\t\t'true_negatives': tn,\n",
    "\t\t'false_positives': fp,\n",
    "\t\t'false_negatives': fn,\n",
    "\t\t'true_positives': tp,\n",
    "\t\t'total_cost': total_cost,\n",
    "\t\t'cost_per_prediction': cost_per_prediction\n",
    "\t}\n",
    "\t\n",
    "\tif verbose:\n",
    "\t\tprint(f\"\\n{model_name} Comprehensive Evaluation\")\n",
    "\t\t\n",
    "\t\tprint(f\"\\nROC-AUC: {roc_auc:.4f}\")\n",
    "\t\tprint(\"Overall discrimination ability\")\n",
    "\t\t\n",
    "\t\tprint(f\"\\nPrecision: {precision:.4f}\")\n",
    "\t\tprint(f\"Recall: {recall:.4f}\")\n",
    "\t\tprint(f\"F1 Score: {f1:.4f}\")\n",
    "\t\tprint(\"Important when default is minority class or false negatives are costly\")\n",
    "\t\t\n",
    "\t\tprint(f\"\\nPR-AUC: {pr_auc:.4f}\")\n",
    "\t\tprint(\"Precision-Recall AUC - better than ROC-AUC for class imbalance\")\n",
    "\t\t\n",
    "\t\tprint(f\"\\nConfusion Matrix:\")\n",
    "\t\tprint(f\"                Predicted\")\n",
    "\t\tprint(f\"              No Default  Default\")\n",
    "\t\tprint(f\"Actual No Default    {tn:5d}     {fp:5d}\")\n",
    "\t\tprint(f\"       Default       {fn:5d}     {tp:5d}\")\n",
    "\t\tprint(f\"\\nFalse Positives: {fp}\")\n",
    "\t\tprint(f\"False Negatives: {fn}\")\n",
    "\t\t\n",
    "\t\tprint(f\"\\nBrier Score: {brier_score:.4f}\")\n",
    "\t\tprint(\"Lower is better - measures probabilistic prediction quality\")\n",
    "\t\t\n",
    "\t\tprint(f\"\\nCost Analysis:\")\n",
    "\t\tprint(f\"Cost per False Positive: ${cost_false_positive:,.2f}\")\n",
    "\t\tprint(f\"Cost per False Negative: ${cost_false_negative:,.2f}\")\n",
    "\t\tprint(f\"Total False Positives: {fp}\")\n",
    "\t\tprint(f\"Total False Negatives: {fn}\")\n",
    "\t\tprint(f\"Total Business Cost: ${total_cost:,.2f}\")\n",
    "\t\tprint(f\"Cost per Prediction: ${cost_per_prediction:,.2f}\")\n",
    "\t\tprint(f\"\\nPotential writeoff (if all defaults missed): ${fn * cost_false_negative:,.2f}\")\n",
    "\t\tprint(f\"Potential payback (if all correctly identified): ${tp * cost_false_negative:,.2f}\")\n",
    "\t\n",
    "\treturn results\n",
    "\n",
    "def predict_default_probability(model, LIMIT_BAL=None, SEX=None, EDUCATION=None, MARRIAGE=None, \n",
    "\t\t\t\t\t   AGE=None, PAY_0=None, PAY_2=None, PAY_3=None, PAY_4=None, \n",
    "\t\t\t\t\t   PAY_5=None, PAY_6=None, BILL_AMT1=None, BILL_AMT2=None, \n",
    "\t\t\t\t\t   BILL_AMT3=None, BILL_AMT4=None, BILL_AMT5=None, BILL_AMT6=None,\n",
    "\t\t\t\t\t   PAY_AMT1=None, PAY_AMT2=None, PAY_AMT3=None, PAY_AMT4=None,\n",
    "\t\t\t\t\t   PAY_AMT5=None, PAY_AMT6=None, feature_names=None, scaler=None):\n",
    "\t\"\"\"\n",
    "\tPredict default probability for a hypothetical person.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tmodel: Trained model\n",
    "\t\tLIMIT_BAL: Credit limit balance\n",
    "\t\tSEX: Sex (1=male, 2=female)\n",
    "\t\tEDUCATION: Education level (1=graduate, 2=university, 3=high school, 4=others)\n",
    "\t\tMARRIAGE: Marital status (1=married, 2=single, 3=others)\n",
    "\t\tAGE: Age in years\n",
    "\t\tPAY_0 through PAY_6: Payment status (-1=pay duly, 0=no consumption, 1+=months overdue)\n",
    "\t\tBILL_AMT1 through BILL_AMT6: Bill statement amounts\n",
    "\t\tPAY_AMT1 through PAY_AMT6: Previous payment amounts\n",
    "\t\tfeature_names: List of feature names in the order expected by the model\n",
    "\t\tscaler: Scaler object (StandardScaler or RobustScaler) used during training. Required if models were trained on scaled data.\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tProbability of default (0-1)\n",
    "\t\"\"\"\n",
    "\tif feature_names is None:\n",
    "\t\traise ValueError(\"feature_names must be provided - use X_train.columns.tolist() from your training data\")\n",
    "\t\n",
    "\tfeature_dict = {\n",
    "\t\t'LIMIT_BAL': LIMIT_BAL,\n",
    "\t\t'SEX': SEX,\n",
    "\t\t'EDUCATION': EDUCATION,\n",
    "\t\t'MARRIAGE': MARRIAGE,\n",
    "\t\t'AGE': AGE,\n",
    "\t\t'PAY_0': PAY_0,\n",
    "\t\t'PAY_2': PAY_2,\n",
    "\t\t'PAY_3': PAY_3,\n",
    "\t\t'PAY_4': PAY_4,\n",
    "\t\t'PAY_5': PAY_5,\n",
    "\t\t'PAY_6': PAY_6,\n",
    "\t\t'BILL_AMT1': BILL_AMT1,\n",
    "\t\t'BILL_AMT2': BILL_AMT2,\n",
    "\t\t'BILL_AMT3': BILL_AMT3,\n",
    "\t\t'BILL_AMT4': BILL_AMT4,\n",
    "\t\t'BILL_AMT5': BILL_AMT5,\n",
    "\t\t'BILL_AMT6': BILL_AMT6,\n",
    "\t\t'PAY_AMT1': PAY_AMT1,\n",
    "\t\t'PAY_AMT2': PAY_AMT2,\n",
    "\t\t'PAY_AMT3': PAY_AMT3,\n",
    "\t\t'PAY_AMT4': PAY_AMT4,\n",
    "\t\t'PAY_AMT5': PAY_AMT5,\n",
    "\t\t'PAY_AMT6': PAY_AMT6\n",
    "\t}\n",
    "\t\n",
    "\tfeature_values = []\n",
    "\tfor feature in feature_names:\n",
    "\t\tif feature in feature_dict:\n",
    "\t\t\tvalue = feature_dict[feature]\n",
    "\t\t\tif value is None:\n",
    "\t\t\t\traise ValueError(f\"Missing required feature: {feature}\")\n",
    "\t\t\tfeature_values.append(value)\n",
    "\t\telse:\n",
    "\t\t\tif feature == 'default_payment_next_month':\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif feature.startswith('SEX_') or feature.startswith('EDUCATION_') or feature.startswith('MARRIAGE_'):\n",
    "\t\t\t\tbase_feature = feature.split('_')[0]\n",
    "\t\t\t\tif base_feature == 'SEX' and SEX is not None:\n",
    "\t\t\t\t\tfeature_values.append(1 if feature == f'SEX_{SEX}' else 0)\n",
    "\t\t\t\telif base_feature == 'EDUCATION' and EDUCATION is not None:\n",
    "\t\t\t\t\tfeature_values.append(1 if feature == f'EDUCATION_{EDUCATION}' else 0)\n",
    "\t\t\t\telif base_feature == 'MARRIAGE' and MARRIAGE is not None:\n",
    "\t\t\t\t\tfeature_values.append(1 if feature == f'MARRIAGE_{MARRIAGE}' else 0)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tfeature_values.append(0)\n",
    "\t\t\telif 'total_bills_paid_to_date' in feature:\n",
    "\t\t\t\tif PAY_AMT1 is not None:\n",
    "\t\t\t\t\tfeature_values.append(sum([PAY_AMT1 or 0, PAY_AMT2 or 0, PAY_AMT3 or 0, \n",
    "\t\t\t\t\t\t\t\t\t\t\t  PAY_AMT4 or 0, PAY_AMT5 or 0, PAY_AMT6 or 0]))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tfeature_values.append(0)\n",
    "\t\t\telif 'avg_bill' in feature:\n",
    "\t\t\t\tif BILL_AMT1 is not None:\n",
    "\t\t\t\t\tbills = [BILL_AMT1 or 0, BILL_AMT2 or 0, BILL_AMT3 or 0, \n",
    "\t\t\t\t\t\t\tBILL_AMT4 or 0, BILL_AMT5 or 0, BILL_AMT6 or 0]\n",
    "\t\t\t\t\tfeature_values.append(np.mean(bills))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tfeature_values.append(0)\n",
    "\t\t\telif 'current_outstanding' in feature:\n",
    "\t\t\t\tif BILL_AMT1 is not None:\n",
    "\t\t\t\t\tfeature_values.append(sum([BILL_AMT1 or 0, BILL_AMT2 or 0, BILL_AMT3 or 0, \n",
    "\t\t\t\t\t\t\t\t\t\t\t  BILL_AMT4 or 0, BILL_AMT5 or 0, BILL_AMT6 or 0]))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tfeature_values.append(0)\n",
    "\t\t\telif 'amortised_debt' in feature:\n",
    "\t\t\t\tif BILL_AMT1 is not None and PAY_AMT1 is not None:\n",
    "\t\t\t\t\tbills = sum([BILL_AMT1 or 0, BILL_AMT2 or 0, BILL_AMT3 or 0, \n",
    "\t\t\t\t\t\t\t\tBILL_AMT4 or 0, BILL_AMT5 or 0, BILL_AMT6 or 0])\n",
    "\t\t\t\t\tpayments = sum([PAY_AMT1 or 0, PAY_AMT2 or 0, PAY_AMT3 or 0, \n",
    "\t\t\t\t\t\t\t\t   PAY_AMT4 or 0, PAY_AMT5 or 0, PAY_AMT6 or 0])\n",
    "\t\t\t\t\tfeature_values.append(max(0, bills - payments))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tfeature_values.append(0)\n",
    "\t\t\telif 'avg_overdue_months' in feature:\n",
    "\t\t\t\tif PAY_0 is not None:\n",
    "\t\t\t\t\tpay_status = [PAY_0 or 0, PAY_2 or 0, PAY_3 or 0, PAY_4 or 0, PAY_5 or 0, PAY_6 or 0]\n",
    "\t\t\t\t\tfeature_values.append(np.mean(pay_status))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tfeature_values.append(0)\n",
    "\t\t\telif 'max_overdue_months' in feature:\n",
    "\t\t\t\tif PAY_0 is not None:\n",
    "\t\t\t\t\tpay_status = [PAY_0 or 0, PAY_2 or 0, PAY_3 or 0, PAY_4 or 0, PAY_5 or 0, PAY_6 or 0]\n",
    "\t\t\t\t\tfeature_values.append(max(pay_status))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tfeature_values.append(0)\n",
    "\t\t\telif 'months_overdue_count' in feature:\n",
    "\t\t\t\tif PAY_0 is not None:\n",
    "\t\t\t\t\tpay_status = [PAY_0 or 0, PAY_2 or 0, PAY_3 or 0, PAY_4 or 0, PAY_5 or 0, PAY_6 or 0]\n",
    "\t\t\t\t\tfeature_values.append(sum(1 for p in pay_status if p > 0))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tfeature_values.append(0)\n",
    "\t\t\telif 'credit_utilisation' in feature:\n",
    "\t\t\t\tif LIMIT_BAL is not None and LIMIT_BAL > 0:\n",
    "\t\t\t\t\tif BILL_AMT1 is not None:\n",
    "\t\t\t\t\t\tbills = sum([BILL_AMT1 or 0, BILL_AMT2 or 0, BILL_AMT3 or 0, \n",
    "\t\t\t\t\t\t\t\t\tBILL_AMT4 or 0, BILL_AMT5 or 0, BILL_AMT6 or 0])\n",
    "\t\t\t\t\t\tfeature_values.append(min(1.0, bills / LIMIT_BAL))\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tfeature_values.append(0)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tfeature_values.append(0)\n",
    "\t\t\telse:\n",
    "\t\t\t\tfeature_values.append(0)\n",
    "\t\n",
    "\tfeature_array = np.array([feature_values])\n",
    "\t\n",
    "\t# Apply scaling if scaler is provided (models were trained on scaled data)\n",
    "\tif scaler is not None:\n",
    "\t\tfeature_array = scaler.transform(feature_array)\n",
    "\t\n",
    "\tprobability = model.predict_proba(feature_array)[0, 1]\n",
    "\t\n",
    "\treturn probability\n",
    "\n",
    "def cross_validate_models(models_dict, X_train, y_train, cv=5, random_state=42, verbose=True):\n",
    "\t\"\"\"\n",
    "\tCross-validate all models using the same stratified CV folds for fairness.\n",
    "\tReports ROC-AUC and PR-AUC with mean  std.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tmodels_dict: Dictionary of trained models\n",
    "\t\tX_train: Training features\n",
    "\t\ty_train: Training target\n",
    "\t\tcv: Number of CV folds\n",
    "\t\trandom_state: Random seed\n",
    "\t\tverbose: If True, print results\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tDictionary with CV results for each model\n",
    "\t\"\"\"\n",
    "\tcv_fold = StratifiedKFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
    "\tresults = {}\n",
    "\t\n",
    "\tif verbose:\n",
    "\t\tprint(\"\\nCross-Validation Evaluation (Same Folds for All Models)\")\n",
    "\t\n",
    "\tfor model_name, model in models_dict.items():\n",
    "\t\troc_auc_scores = []\n",
    "\t\tpr_auc_scores = []\n",
    "\t\t\n",
    "\t\tmodel_clone = clone(model)\n",
    "\t\t\n",
    "\t\tfor fold_idx, (train_idx, val_idx) in enumerate(cv_fold.split(X_train, y_train)):\n",
    "\t\t\tif isinstance(X_train, pd.DataFrame):\n",
    "\t\t\t\tX_fold_train = X_train.iloc[train_idx]\n",
    "\t\t\t\tX_fold_val = X_train.iloc[val_idx]\n",
    "\t\t\telse:\n",
    "\t\t\t\tX_fold_train = X_train[train_idx]\n",
    "\t\t\t\tX_fold_val = X_train[val_idx]\n",
    "\t\t\t\n",
    "\t\t\tif isinstance(y_train, pd.Series):\n",
    "\t\t\t\ty_fold_train = y_train.iloc[train_idx]\n",
    "\t\t\t\ty_fold_val = y_train.iloc[val_idx]\n",
    "\t\t\telse:\n",
    "\t\t\t\ty_fold_train = y_train[train_idx]\n",
    "\t\t\t\ty_fold_val = y_train[val_idx]\n",
    "\t\t\t\n",
    "\t\t\tmodel_clone.fit(X_fold_train, y_fold_train)\n",
    "\t\t\ty_proba = model_clone.predict_proba(X_fold_val)[:, 1]\n",
    "\t\t\t\n",
    "\t\t\troc_auc = roc_auc_score(y_fold_val, y_proba)\n",
    "\t\t\tpr_auc = average_precision_score(y_fold_val, y_proba)\n",
    "\t\t\t\n",
    "\t\t\troc_auc_scores.append(roc_auc)\n",
    "\t\t\tpr_auc_scores.append(pr_auc)\n",
    "\t\t\n",
    "\t\troc_mean = np.mean(roc_auc_scores)\n",
    "\t\troc_std = np.std(roc_auc_scores)\n",
    "\t\tpr_mean = np.mean(pr_auc_scores)\n",
    "\t\tpr_std = np.std(pr_auc_scores)\n",
    "\t\t\n",
    "\t\tresults[model_name] = {\n",
    "\t\t\t'roc_auc_scores': roc_auc_scores,\n",
    "\t\t\t'pr_auc_scores': pr_auc_scores,\n",
    "\t\t\t'roc_auc_mean': roc_mean,\n",
    "\t\t\t'roc_auc_std': roc_std,\n",
    "\t\t\t'pr_auc_mean': pr_mean,\n",
    "\t\t\t'pr_auc_std': pr_std\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\tif verbose:\n",
    "\t\t\tdisplay_name = {\n",
    "\t\t\t\t'logistic_regression': 'Logistic Regression',\n",
    "\t\t\t\t'random_forest': 'Random Forest',\n",
    "\t\t\t\t'gradient_boosting': 'Gradient Boosting',\n",
    "\t\t\t\t'neural_network': 'Neural Network',\n",
    "\t\t\t\t'stacked_model': 'Stacked Ensemble'\n",
    "\t\t\t}.get(model_name, model_name)\n",
    "\t\t\t\n",
    "\t\t\tprint(f\"\\n{display_name}:\")\n",
    "\t\t\tprint(f\"  ROC-AUC: {roc_mean:.4f}  {roc_std:.4f}\")\n",
    "\t\t\tprint(f\"  PR-AUC:  {pr_mean:.4f}  {pr_std:.4f}\")\n",
    "\t\n",
    "\treturn results\n",
    "\n",
    "def mcnemar_test(y_true, y_pred1, y_pred2):\n",
    "\t\"\"\"\n",
    "\tMcNemar's test for comparing two classifiers on the same dataset.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\ty_true: True labels\n",
    "\t\ty_pred1: Predictions from model 1\n",
    "\t\ty_pred2: Predictions from model 2\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tchi2 statistic, p-value\n",
    "\t\"\"\"\n",
    "\tcorrect1 = (y_true == y_pred1)\n",
    "\tcorrect2 = (y_true == y_pred2)\n",
    "\t\n",
    "\tb = np.sum((correct1 == False) & (correct2 == True))\n",
    "\tc = np.sum((correct1 == True) & (correct2 == False))\n",
    "\t\n",
    "\tif b + c == 0:\n",
    "\t\treturn 0.0, 1.0\n",
    "\t\n",
    "\tchi2 = ((abs(b - c) - 1) ** 2) / (b + c)\n",
    "\tp_value = 1 - stats.chi2.cdf(chi2, df=1)\n",
    "\t\n",
    "\treturn chi2, p_value\n",
    "\n",
    "def paired_t_test(scores1, scores2):\n",
    "\t\"\"\"\n",
    "\tPaired t-test for comparing two sets of scores (e.g., from CV folds).\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tscores1: Scores from model 1 (array-like)\n",
    "\t\tscores2: Scores from model 2 (array-like)\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tt statistic, p-value\n",
    "\t\"\"\"\n",
    "\tscores1 = np.array(scores1)\n",
    "\tscores2 = np.array(scores2)\n",
    "\t\n",
    "\tdifferences = scores1 - scores2\n",
    "\tt_stat, p_value = stats.ttest_1samp(differences, 0)\n",
    "\t\n",
    "\treturn t_stat, p_value\n",
    "\n",
    "def statistical_comparison(models_dict, X_test, y_test, cv_results=None, verbose=True):\n",
    "\t\"\"\"\n",
    "\tPerform McNemar's test and paired t-test to compare models.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tmodels_dict: Dictionary of trained models\n",
    "\t\tX_test: Test features\n",
    "\t\ty_test: Test target\n",
    "\t\tcv_results: Optional CV results from cross_validate_models\n",
    "\t\tverbose: If True, print results\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tDictionary with statistical test results\n",
    "\t\"\"\"\n",
    "\tif verbose:\n",
    "\t\tprint(\"\\nStatistical Model Comparison\")\n",
    "\t\n",
    "\tmodel_names = list(models_dict.keys())\n",
    "\tpredictions = {}\n",
    "\t\n",
    "\tfor model_name, model in models_dict.items():\n",
    "\t\tpredictions[model_name] = model.predict(X_test)\n",
    "\t\n",
    "\tcomparison_results = {}\n",
    "\t\n",
    "\tfor i, model1_name in enumerate(model_names):\n",
    "\t\tfor model2_name in model_names[i+1:]:\n",
    "\t\t\tpred1 = predictions[model1_name]\n",
    "\t\t\tpred2 = predictions[model2_name]\n",
    "\t\t\t\n",
    "\t\t\tchi2, p_mcnemar = mcnemar_test(y_test, pred1, pred2)\n",
    "\t\t\t\n",
    "\t\t\tcomparison_key = f\"{model1_name}_vs_{model2_name}\"\n",
    "\t\t\tcomparison_results[comparison_key] = {\n",
    "\t\t\t\t'mcnemar_chi2': chi2,\n",
    "\t\t\t\t'mcnemar_p': p_mcnemar\n",
    "\t\t\t}\n",
    "\t\t\t\n",
    "\t\t\tif cv_results is not None:\n",
    "\t\t\t\tif model1_name in cv_results and model2_name in cv_results:\n",
    "\t\t\t\t\tt_stat, p_ttest = paired_t_test(\n",
    "\t\t\t\t\t\tcv_results[model1_name]['roc_auc_scores'],\n",
    "\t\t\t\t\t\tcv_results[model2_name]['roc_auc_scores']\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\t\tcomparison_results[comparison_key]['ttest_t'] = t_stat\n",
    "\t\t\t\t\tcomparison_results[comparison_key]['ttest_p'] = p_ttest\n",
    "\t\t\t\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tdisplay1 = {\n",
    "\t\t\t\t\t'logistic_regression': 'Logistic Regression',\n",
    "\t\t\t\t\t'random_forest': 'Random Forest',\n",
    "\t\t\t\t\t'gradient_boosting': 'Gradient Boosting',\n",
    "\t\t\t\t\t'neural_network': 'Neural Network'\n",
    "\t\t\t\t}.get(model1_name, model1_name)\n",
    "\t\t\t\t\n",
    "\t\t\t\tdisplay2 = {\n",
    "\t\t\t\t\t'logistic_regression': 'Logistic Regression',\n",
    "\t\t\t\t\t'random_forest': 'Random Forest',\n",
    "\t\t\t\t\t'gradient_boosting': 'Gradient Boosting',\n",
    "\t\t\t\t\t'neural_network': 'Neural Network'\n",
    "\t\t\t\t}.get(model2_name, model2_name)\n",
    "\t\t\t\t\n",
    "\t\t\t\tprint(f\"\\n{display1} vs {display2}:\")\n",
    "\t\t\t\tprint(f\"  McNemar's test: chi2={chi2:.4f}, p={p_mcnemar:.4f}\")\n",
    "\t\t\t\tif 'ttest_t' in comparison_results[comparison_key]:\n",
    "\t\t\t\t\tprint(f\"  Paired t-test: t={comparison_results[comparison_key]['ttest_t']:.4f}, p={comparison_results[comparison_key]['ttest_p']:.4f}\")\n",
    "\t\n",
    "\treturn comparison_results\n",
    "\n",
    "def plot_feature_importance_and_shap(model, X_train, X_test, feature_names, model_name=\"Model\", \n",
    "\t\t\t\t\t\t\ttop_n=20, save_plots=False, y_test=None):\n",
    "\t\"\"\"\n",
    "\tPlot feature importance and SHAP values for model interpretation.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tmodel: Trained model\n",
    "\t\tX_train: Training features\n",
    "\t\tX_test: Test features (for SHAP)\n",
    "\t\tfeature_names: List of feature names\n",
    "\t\tmodel_name: Name of model for display\n",
    "\t\ttop_n: Number of top features to show\n",
    "\t\tsave_plots: If True, save plots to files\n",
    "\t\ty_test: Test target (needed for permutation importance)\n",
    "\t\"\"\"\n",
    "\timport os\n",
    "\t\n",
    "\t# Create results folder if saving plots\n",
    "\tif save_plots:\n",
    "\t\tos.makedirs('results', exist_ok=True)\n",
    "\t\n",
    "\tif hasattr(model, 'feature_importances_'):\n",
    "\t\tmethod = 'tree'\n",
    "\t\timportance_df = get_feature_importance(model, feature_names, method=method)\n",
    "\telse:\n",
    "\t\tif y_test is not None:\n",
    "\t\t\tmethod = 'permutation'\n",
    "\t\t\timportance_df = get_feature_importance(model, feature_names, method=method, X_test=X_test, y_test=y_test)\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"Warning: y_test not provided, cannot compute permutation importance for {model_name}\")\n",
    "\t\t\treturn\n",
    "\t\n",
    "\ttop_features = importance_df.head(top_n)\n",
    "\t\n",
    "\tplt.figure(figsize=(10, 8))\n",
    "\tplt.barh(range(len(top_features)), top_features['importance'].values)\n",
    "\tplt.yticks(range(len(top_features)), top_features['feature'].values)\n",
    "\tplt.xlabel('Importance')\n",
    "\tplt.title(f'{model_name} - Top {top_n} Feature Importances')\n",
    "\tplt.gca().invert_yaxis()\n",
    "\tplt.tight_layout()\n",
    "\t\n",
    "\tif save_plots:\n",
    "\t\tplt.savefig(f'results/{model_name}_feature_importance.png', dpi=150)\n",
    "\t\tprint(f\"Saved feature importance plot to results/{model_name}_feature_importance.png\")\n",
    "\telse:\n",
    "\t\tplt.show()\n",
    "\t\n",
    "\tplt.close()\n",
    "\t\n",
    "\ttry:\n",
    "\t\tX_test_sample = X_test[:100] if hasattr(X_test, 'iloc') else X_test[:100]\n",
    "\t\tX_train_sample = X_train[:100] if hasattr(X_train, 'iloc') else X_train[:100]\n",
    "\t\t\n",
    "\t\tif hasattr(model, 'feature_importances_'):\n",
    "\t\t\texplainer = shap.TreeExplainer(model)\n",
    "\t\t\tshap_values = explainer.shap_values(X_test_sample)\n",
    "\t\telif hasattr(model, 'coef_'):\n",
    "\t\t\texplainer = shap.LinearExplainer(model, X_train_sample)\n",
    "\t\t\tshap_values = explainer.shap_values(X_test_sample)\n",
    "\t\telse:\n",
    "\t\t\tdef model_predict(X):\n",
    "\t\t\t\treturn model.predict_proba(X)[:, 1]\n",
    "\t\t\texplainer = shap.KernelExplainer(model_predict, X_train_sample)\n",
    "\t\t\tshap_values = explainer.shap_values(X_test_sample)\n",
    "\t\t\n",
    "\t\t# Handle different SHAP value formats\n",
    "\t\tif isinstance(shap_values, list):\n",
    "\t\t\tif len(shap_values) == 2:\n",
    "\t\t\t\t# Binary classification: use positive class (index 1)\n",
    "\t\t\t\tshap_values = shap_values[1]\n",
    "\t\t\telse:\n",
    "\t\t\t\tshap_values = shap_values[0]\n",
    "\t\t\n",
    "\t\tshap_values = np.array(shap_values)\n",
    "\t\t\n",
    "\t\t# Handle 3D arrays (samples, classes, features) - take positive class\n",
    "\t\tif len(shap_values.shape) == 3:\n",
    "\t\t\t# For binary classification, shape is (n_samples, n_classes, n_features)\n",
    "\t\t\t# Take the positive class (index 1) or the last class\n",
    "\t\t\tif shap_values.shape[1] == 2:\n",
    "\t\t\t\tshap_values = shap_values[:, 1, :]  # Take positive class\n",
    "\t\t\telse:\n",
    "\t\t\t\tshap_values = shap_values[:, -1, :]  # Take last class\n",
    "\t\t\n",
    "\t\t# Ensure 2D array (samples, features)\n",
    "\t\tif len(shap_values.shape) == 1:\n",
    "\t\t\tshap_values = shap_values.reshape(1, -1)\n",
    "\t\t\n",
    "\t\t# Convert X_test_sample to numpy array and ensure shapes match\n",
    "\t\tif hasattr(X_test_sample, 'values'):\n",
    "\t\t\tX_test_sample_array = X_test_sample.values\n",
    "\t\telif hasattr(X_test_sample, 'to_numpy'):\n",
    "\t\t\tX_test_sample_array = X_test_sample.to_numpy()\n",
    "\t\telse:\n",
    "\t\t\tX_test_sample_array = np.array(X_test_sample)\n",
    "\t\t\n",
    "\t\t# Ensure both are 2D\n",
    "\t\tif len(X_test_sample_array.shape) == 1:\n",
    "\t\t\tX_test_sample_array = X_test_sample_array.reshape(-1, 1)\n",
    "\t\t\n",
    "\t\t# Ensure both have the same number of samples (should match, but be safe)\n",
    "\t\tif shap_values.shape[0] != X_test_sample_array.shape[0]:\n",
    "\t\t\tmin_samples = min(shap_values.shape[0], X_test_sample_array.shape[0])\n",
    "\t\t\tshap_values = shap_values[:min_samples, :]\n",
    "\t\t\tX_test_sample_array = X_test_sample_array[:min_samples, :]\n",
    "\t\t\n",
    "\t\t# Ensure both have the same number of features\n",
    "\t\tif shap_values.shape[1] != X_test_sample_array.shape[1]:\n",
    "\t\t\tmin_features = min(shap_values.shape[1], X_test_sample_array.shape[1])\n",
    "\t\t\tshap_values = shap_values[:, :min_features]\n",
    "\t\t\tX_test_sample_array = X_test_sample_array[:, :min_features]\n",
    "\t\t\tfeature_names_plot = feature_names[:min_features]\n",
    "\t\telse:\n",
    "\t\t\tfeature_names_plot = feature_names\n",
    "\t\t\n",
    "\t\tplt.figure(figsize=(10, 8))\n",
    "\t\tshap.summary_plot(shap_values, X_test_sample_array, feature_names=feature_names_plot, show=False, max_display=top_n)\n",
    "\t\tplt.title(f'{model_name} - SHAP Summary Plot')\n",
    "\t\tplt.tight_layout()\n",
    "\t\t\n",
    "\t\tif save_plots:\n",
    "\t\t\tplt.savefig(f'results/{model_name}_shap_summary.png', dpi=150, bbox_inches='tight')\n",
    "\t\t\tprint(f\"Saved SHAP summary plot to results/{model_name}_shap_summary.png\")\n",
    "\t\telse:\n",
    "\t\t\tplt.show()\n",
    "\t\t\n",
    "\t\tplt.close()\n",
    "\t\t\n",
    "\t\t# SHAP Bar Plot - use already processed shap_values\n",
    "\t\ttry:\n",
    "\t\t\t# shap_values is already processed to 2D array (samples, features)\n",
    "\t\t\t# Calculate mean absolute SHAP values per feature\n",
    "\t\t\tmean_shap = np.abs(shap_values).mean(axis=0)  # Mean across samples\n",
    "\t\t\t\n",
    "\t\t\t# Ensure feature names match\n",
    "\t\t\tif len(mean_shap) != len(feature_names):\n",
    "\t\t\t\tmin_len = min(len(mean_shap), len(feature_names))\n",
    "\t\t\t\tmean_shap = mean_shap[:min_len]\n",
    "\t\t\t\tfeature_names_use = feature_names[:min_len]\n",
    "\t\t\telse:\n",
    "\t\t\t\tfeature_names_use = feature_names\n",
    "\t\t\t\n",
    "\t\t\t# Get top N features\n",
    "\t\t\ttop_indices = np.argsort(mean_shap)[::-1][:top_n]\n",
    "\t\t\ttop_mean_shap = mean_shap[top_indices]\n",
    "\t\t\ttop_feature_names = [feature_names_use[i] for i in top_indices]\n",
    "\t\t\t\n",
    "\t\t\t# Create bar plot manually\n",
    "\t\t\tplt.figure(figsize=(10, 8))\n",
    "\t\t\tplt.barh(range(len(top_indices)), top_mean_shap)\n",
    "\t\t\tplt.yticks(range(len(top_indices)), top_feature_names)\n",
    "\t\t\tplt.xlabel('Mean |SHAP value|')\n",
    "\t\t\tplt.title(f'{model_name} - SHAP Bar Plot')\n",
    "\t\t\tplt.gca().invert_yaxis()\n",
    "\t\t\tplt.tight_layout()\n",
    "\t\t\t\n",
    "\t\t\tif save_plots:\n",
    "\t\t\t\tplt.savefig(f'results/{model_name}_shap_bar.png', dpi=150, bbox_inches='tight')\n",
    "\t\t\t\tprint(f\"Saved SHAP bar plot to results/{model_name}_shap_bar.png\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tplt.show()\n",
    "\t\t\t\n",
    "\t\t\tplt.close()\n",
    "\t\texcept Exception as bar_error:\n",
    "\t\t\tprint(f\"Warning: Could not generate SHAP bar plot: {bar_error}\")\n",
    "\t\t\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error generating SHAP plots: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eceab9",
   "metadata": {},
   "source": [
    "## Execute Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0022be8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed columns:\n",
      "  X1 -> LIMIT_BAL\n",
      "  X2 -> SEX\n",
      "  X3 -> EDUCATION\n",
      "  X4 -> MARRIAGE\n",
      "  X5 -> AGE\n",
      "  X6 -> PAY_0\n",
      "  X7 -> PAY_2\n",
      "  X8 -> PAY_3\n",
      "  X9 -> PAY_4\n",
      "  X10 -> PAY_5\n",
      "  X11 -> PAY_6\n",
      "  X12 -> BILL_AMT1\n",
      "  X13 -> BILL_AMT2\n",
      "  X14 -> BILL_AMT3\n",
      "  X15 -> BILL_AMT4\n",
      "  X16 -> BILL_AMT5\n",
      "  X17 -> BILL_AMT6\n",
      "  X18 -> PAY_AMT1\n",
      "  X19 -> PAY_AMT2\n",
      "  X20 -> PAY_AMT3\n",
      "  X21 -> PAY_AMT4\n",
      "  X22 -> PAY_AMT5\n",
      "  X23 -> PAY_AMT6\n",
      "  Y -> default_payment_next_month\n",
      "\n",
      "INITIAL DATA EXPLORATION\n",
      "\n",
      "DataFrame head:\n",
      "  Unnamed: 0  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
      "0         ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3   \n",
      "1          1      20000    2          2         1   24      2      2     -1   \n",
      "2          2     120000    2          2         2   26     -1      2      0   \n",
      "3          3      90000    2          2         2   34      0      0      0   \n",
      "4          4      50000    2          2         1   37      0      0      0   \n",
      "\n",
      "   PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3   \n",
      "1     -1  ...          0          0          0         0       689         0   \n",
      "2      0  ...       3272       3455       3261         0      1000      1000   \n",
      "3      0  ...      14331      14948      15549      1518      1500      1000   \n",
      "4      0  ...      28314      28959      29547      2000      2019      1200   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default_payment_next_month  \n",
      "0  PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
      "1         0         0         0                           1  \n",
      "2      1000         0      2000                           1  \n",
      "3      1000      1000      5000                           0  \n",
      "4      1100      1069      1000                           0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "DataFrame tail:\n",
      "      Unnamed: 0 LIMIT_BAL SEX EDUCATION MARRIAGE AGE PAY_0 PAY_2 PAY_3 PAY_4  \\\n",
      "29996      29996    220000   1         3        1  39     0     0     0     0   \n",
      "29997      29997    150000   1         3        2  43    -1    -1    -1    -1   \n",
      "29998      29998     30000   1         2        2  37     4     3     2    -1   \n",
      "29999      29999     80000   1         3        1  41     1    -1     0     0   \n",
      "30000      30000     50000   1         2        1  46     0     0     0     0   \n",
      "\n",
      "       ... BILL_AMT4 BILL_AMT5 BILL_AMT6 PAY_AMT1 PAY_AMT2 PAY_AMT3 PAY_AMT4  \\\n",
      "29996  ...     88004     31237     15980     8500    20000     5003     3047   \n",
      "29997  ...      8979      5190         0     1837     3526     8998      129   \n",
      "29998  ...     20878     20582     19357        0        0    22000     4200   \n",
      "29999  ...     52774     11855     48944    85900     3409     1178     1926   \n",
      "30000  ...     36535     32428     15313     2078     1800     1430     1000   \n",
      "\n",
      "      PAY_AMT5 PAY_AMT6 default_payment_next_month  \n",
      "29996     5000     1000                          0  \n",
      "29997        0        0                          0  \n",
      "29998     2000     3100                          1  \n",
      "29999    52964     1804                          1  \n",
      "30000     1000     1000                          1  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30001 entries, 0 to 30000\n",
      "Data columns (total 25 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   Unnamed: 0                  30001 non-null  object\n",
      " 1   LIMIT_BAL                   30001 non-null  object\n",
      " 2   SEX                         30001 non-null  object\n",
      " 3   EDUCATION                   30001 non-null  object\n",
      " 4   MARRIAGE                    30001 non-null  object\n",
      " 5   AGE                         30001 non-null  object\n",
      " 6   PAY_0                       30001 non-null  object\n",
      " 7   PAY_2                       30001 non-null  object\n",
      " 8   PAY_3                       30001 non-null  object\n",
      " 9   PAY_4                       30001 non-null  object\n",
      " 10  PAY_5                       30001 non-null  object\n",
      " 11  PAY_6                       30001 non-null  object\n",
      " 12  BILL_AMT1                   30001 non-null  object\n",
      " 13  BILL_AMT2                   30001 non-null  object\n",
      " 14  BILL_AMT3                   30001 non-null  object\n",
      " 15  BILL_AMT4                   30001 non-null  object\n",
      " 16  BILL_AMT5                   30001 non-null  object\n",
      " 17  BILL_AMT6                   30001 non-null  object\n",
      " 18  PAY_AMT1                    30001 non-null  object\n",
      " 19  PAY_AMT2                    30001 non-null  object\n",
      " 20  PAY_AMT3                    30001 non-null  object\n",
      " 21  PAY_AMT4                    30001 non-null  object\n",
      " 22  PAY_AMT5                    30001 non-null  object\n",
      " 23  PAY_AMT6                    30001 non-null  object\n",
      " 24  default_payment_next_month  30001 non-null  object\n",
      "dtypes: object(25)\n",
      "memory usage: 5.7+ MB\n",
      "\n",
      "DataFrame info:\n",
      "None\n",
      "\n",
      "DataFrame describe:\n",
      "        Unnamed: 0  LIMIT_BAL    SEX  EDUCATION  MARRIAGE    AGE  PAY_0  \\\n",
      "count        30001      30001  30001      30001     30001  30001  30001   \n",
      "unique       30001         82      3          8         5     57     12   \n",
      "top          30000      50000      2          2         2     29      0   \n",
      "freq             1       3365  18112      14030     15964   1605  14737   \n",
      "\n",
      "        PAY_2  PAY_3  PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  \\\n",
      "count   30001  30001  30001  ...      30001      30001      30001     30001   \n",
      "unique     12     12     12  ...      21549      21011      20605      7944   \n",
      "top         0      0      0  ...          0          0          0         0   \n",
      "freq    15730  15764  16455  ...       3195       3506       4020      5249   \n",
      "\n",
      "        PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
      "count      30001     30001     30001     30001     30001   \n",
      "unique      7900      7519      6938      6898      6940   \n",
      "top            0         0         0         0         0   \n",
      "freq        5396      5968      6408      6703      7173   \n",
      "\n",
      "        default_payment_next_month  \n",
      "count                        30001  \n",
      "unique                           3  \n",
      "top                              0  \n",
      "freq                         23364  \n",
      "\n",
      "[4 rows x 25 columns]\n",
      "\n",
      "DataFrame shape: 30001 rows, 25 columns\n",
      "Expected size: ~30,000 rows\n",
      "Dataset size looks good\n",
      "\n",
      "DataFrame columns:\n",
      "['Unnamed: 0', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'default_payment_next_month']\n",
      "['Unnamed: 0', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'default_payment_next_month']\n",
      "\n",
      "DataFrame dtypes:\n",
      "Unnamed: 0                    object\n",
      "LIMIT_BAL                     object\n",
      "SEX                           object\n",
      "EDUCATION                     object\n",
      "MARRIAGE                      object\n",
      "AGE                           object\n",
      "PAY_0                         object\n",
      "PAY_2                         object\n",
      "PAY_3                         object\n",
      "PAY_4                         object\n",
      "PAY_5                         object\n",
      "PAY_6                         object\n",
      "BILL_AMT1                     object\n",
      "BILL_AMT2                     object\n",
      "BILL_AMT3                     object\n",
      "BILL_AMT4                     object\n",
      "BILL_AMT5                     object\n",
      "BILL_AMT6                     object\n",
      "PAY_AMT1                      object\n",
      "PAY_AMT2                      object\n",
      "PAY_AMT3                      object\n",
      "PAY_AMT4                      object\n",
      "PAY_AMT5                      object\n",
      "PAY_AMT6                      object\n",
      "default_payment_next_month    object\n",
      "dtype: object\n",
      "\n",
      "Missing values count:\n",
      "Unnamed: 0                    0\n",
      "LIMIT_BAL                     0\n",
      "SEX                           0\n",
      "EDUCATION                     0\n",
      "MARRIAGE                      0\n",
      "AGE                           0\n",
      "PAY_0                         0\n",
      "PAY_2                         0\n",
      "PAY_3                         0\n",
      "PAY_4                         0\n",
      "PAY_5                         0\n",
      "PAY_6                         0\n",
      "BILL_AMT1                     0\n",
      "BILL_AMT2                     0\n",
      "BILL_AMT3                     0\n",
      "BILL_AMT4                     0\n",
      "BILL_AMT5                     0\n",
      "BILL_AMT6                     0\n",
      "PAY_AMT1                      0\n",
      "PAY_AMT2                      0\n",
      "PAY_AMT3                      0\n",
      "PAY_AMT4                      0\n",
      "PAY_AMT5                      0\n",
      "PAY_AMT6                      0\n",
      "default_payment_next_month    0\n",
      "dtype: int64\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Duplicate rows:\n",
      "0\n",
      "REMOVING UNNECESSARY COLUMNS\n",
      "Dropping columns: ['Unnamed: 0']\n",
      "HANDLING MISSING VALUES\n",
      "No missing values found\n",
      "\n",
      "Shape after handling missing values: (30001, 24)\n",
      "CORRECTING TYPES AND ENCODING\n",
      "Converting LIMIT_BAL from string to int (30000 values converted)\n",
      "Converting SEX from string to int (30000 values converted)\n",
      "Converting EDUCATION from string to int (30000 values converted)\n",
      "Converting MARRIAGE from string to int (30000 values converted)\n",
      "Converting AGE from string to int (30000 values converted)\n",
      "Converting PAY_0 from string to int (30000 values converted)\n",
      "Converting PAY_2 from string to int (30000 values converted)\n",
      "Converting PAY_3 from string to int (30000 values converted)\n",
      "Converting PAY_4 from string to int (30000 values converted)\n",
      "Converting PAY_5 from string to int (30000 values converted)\n",
      "Converting PAY_6 from string to int (30000 values converted)\n",
      "Converting BILL_AMT1 from string to int (30000 values converted)\n",
      "Converting BILL_AMT2 from string to int (30000 values converted)\n",
      "Converting BILL_AMT3 from string to int (30000 values converted)\n",
      "Converting BILL_AMT4 from string to int (30000 values converted)\n",
      "Converting BILL_AMT5 from string to int (30000 values converted)\n",
      "Converting BILL_AMT6 from string to int (30000 values converted)\n",
      "Converting PAY_AMT1 from string to int (30000 values converted)\n",
      "Converting PAY_AMT2 from string to int (30000 values converted)\n",
      "Converting PAY_AMT3 from string to int (30000 values converted)\n",
      "Converting PAY_AMT4 from string to int (30000 values converted)\n",
      "Converting PAY_AMT5 from string to int (30000 values converted)\n",
      "Converting PAY_AMT6 from string to int (30000 values converted)\n",
      "Converting default_payment_next_month from string to int (30000 values converted)\n",
      "Total columns converted from string to int: 24\n",
      "\n",
      "One-hot encoding nominal categories: ['SEX', 'EDUCATION', 'MARRIAGE']\n",
      "  -> Encoded SEX into 2 binary columns\n",
      "  -> Encoded EDUCATION into 6 binary columns\n",
      "  -> Encoded MARRIAGE into 3 binary columns\n",
      "\n",
      "Payment status columns (keeping as ordinal): ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
      "  -> PAY_0 kept as ordinal (int)\n",
      "  -> PAY_2 kept as ordinal (int)\n",
      "  -> PAY_3 kept as ordinal (int)\n",
      "  -> PAY_4 kept as ordinal (int)\n",
      "  -> PAY_5 kept as ordinal (int)\n",
      "  -> PAY_6 kept as ordinal (int)\n",
      "  -> PAY_AMT1 kept as ordinal (int)\n",
      "  -> PAY_AMT2 kept as ordinal (int)\n",
      "  -> PAY_AMT3 kept as ordinal (int)\n",
      "  -> PAY_AMT4 kept as ordinal (int)\n",
      "  -> PAY_AMT5 kept as ordinal (int)\n",
      "  -> PAY_AMT6 kept as ordinal (int)\n",
      "Converting default_payment_next_month to category for memory efficiency\n",
      "\n",
      "Shape after type corrections: (30001, 32)\n",
      "REMOVING OUTLIERS\n",
      "Using 2-SD method:\n",
      "  LIMIT_BAL: 1558 outliers (|z| > 2)\n",
      "  AGE: 1301 outliers (|z| > 2)\n",
      "  PAY_0: 463 outliers (|z| > 2)\n",
      "  PAY_2: 483 outliers (|z| > 2)\n",
      "  PAY_3: 390 outliers (|z| > 2)\n",
      "  PAY_4: 349 outliers (|z| > 2)\n",
      "  PAY_5: 342 outliers (|z| > 2)\n",
      "  PAY_6: 313 outliers (|z| > 2)\n",
      "  BILL_AMT1: 1558 outliers (|z| > 2)\n",
      "  BILL_AMT2: 1562 outliers (|z| > 2)\n",
      "  BILL_AMT3: 1541 outliers (|z| > 2)\n",
      "  BILL_AMT4: 1551 outliers (|z| > 2)\n",
      "  BILL_AMT5: 1585 outliers (|z| > 2)\n",
      "  BILL_AMT6: 1575 outliers (|z| > 2)\n",
      "  PAY_AMT1: 625 outliers (|z| > 2)\n",
      "  PAY_AMT2: 445 outliers (|z| > 2)\n",
      "  PAY_AMT3: 565 outliers (|z| > 2)\n",
      "  PAY_AMT4: 652 outliers (|z| > 2)\n",
      "  PAY_AMT5: 631 outliers (|z| > 2)\n",
      "  PAY_AMT6: 645 outliers (|z| > 2)\n",
      "Using IQR method:\n",
      "  LIMIT_BAL: 167 outliers (outside IQR bounds)\n",
      "  AGE: 273 outliers (outside IQR bounds)\n",
      "  PAY_0: 3130 outliers (outside IQR bounds)\n",
      "  PAY_2: 4410 outliers (outside IQR bounds)\n",
      "  PAY_3: 4209 outliers (outside IQR bounds)\n",
      "  PAY_4: 3508 outliers (outside IQR bounds)\n",
      "  PAY_5: 2968 outliers (outside IQR bounds)\n",
      "  PAY_6: 3079 outliers (outside IQR bounds)\n",
      "  BILL_AMT1: 2400 outliers (outside IQR bounds)\n",
      "  BILL_AMT2: 2395 outliers (outside IQR bounds)\n",
      "  BILL_AMT3: 2469 outliers (outside IQR bounds)\n",
      "  BILL_AMT4: 2622 outliers (outside IQR bounds)\n",
      "  BILL_AMT5: 2726 outliers (outside IQR bounds)\n",
      "  BILL_AMT6: 2693 outliers (outside IQR bounds)\n",
      "  PAY_AMT1: 2745 outliers (outside IQR bounds)\n",
      "  PAY_AMT2: 2714 outliers (outside IQR bounds)\n",
      "  PAY_AMT3: 2598 outliers (outside IQR bounds)\n",
      "  PAY_AMT4: 2994 outliers (outside IQR bounds)\n",
      "  PAY_AMT5: 2944 outliers (outside IQR bounds)\n",
      "  PAY_AMT6: 2958 outliers (outside IQR bounds)\n",
      "\n",
      "Total unique outlier rows: 17667\n",
      "\n",
      "Winsorizing extreme values (1st and 99th percentiles):\n",
      "  LIMIT_BAL: 207 values clipped (min: 0.00->10000.00, max: 1000000.00->500000.00)\n",
      "  AGE: 340 values clipped (min: 0.00->22.00, max: 79.00->60.00)\n",
      "  PAY_0: 141 values clipped (min: -2.00->-2.00, max: 8.00->3.00)\n",
      "  PAY_2: 157 values clipped (min: -2.00->-2.00, max: 8.00->3.00)\n",
      "  PAY_3: 150 values clipped (min: -2.00->-2.00, max: 8.00->3.00)\n",
      "  PAY_4: 169 values clipped (min: -2.00->-2.00, max: 8.00->3.00)\n",
      "  PAY_5: 164 values clipped (min: -2.00->-2.00, max: 8.00->3.00)\n",
      "  PAY_6: 129 values clipped (min: -2.00->-2.00, max: 8.00->3.00)\n",
      "  BILL_AMT1: 599 values clipped (min: -165580.00->-81.00, max: 964511.00->350110.00)\n",
      "  BILL_AMT2: 573 values clipped (min: -69777.00->-200.00, max: 983931.00->337495.00)\n",
      "  BILL_AMT3: 583 values clipped (min: -157264.00->-200.00, max: 1664089.00->325024.00)\n",
      "  BILL_AMT4: 600 values clipped (min: -170000.00->-212.00, max: 891586.00->304997.00)\n",
      "  BILL_AMT5: 600 values clipped (min: -81334.00->-232.00, max: 927171.00->285868.00)\n",
      "  BILL_AMT6: 600 values clipped (min: -339603.00->-331.00, max: 961664.00->279503.00)\n",
      "  PAY_AMT1: 300 values clipped (min: 0.00->0.00, max: 873552.00->66513.00)\n",
      "  PAY_AMT2: 300 values clipped (min: 0.00->0.00, max: 1684259.00->76651.00)\n",
      "  PAY_AMT3: 297 values clipped (min: 0.00->0.00, max: 896040.00->70000.00)\n",
      "  PAY_AMT4: 300 values clipped (min: 0.00->0.00, max: 621000.00->67052.00)\n",
      "  PAY_AMT5: 300 values clipped (min: 0.00->0.00, max: 426529.00->65607.00)\n",
      "  PAY_AMT6: 300 values clipped (min: 0.00->0.00, max: 528666.00->82615.00)\n",
      "\n",
      "Total values winsorized across all columns: 6809\n",
      "\n",
      "Grouping rare categorical values into 'Other':\n",
      "\n",
      "Shape after anomaly handling: (30001, 32) (removed 0 rows)\n",
      "CREATING DERIVED FEATURES\n",
      "Found bill columns: ['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']\n",
      "Found payment amount columns: ['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
      "Created: total_bills_paid_to_date\n",
      "Created: avg_bill\n",
      "Created: current_outstanding\n",
      "Created: amortised_debt\n",
      "Create: avg_overdue_months\n",
      "Created: max_overdue_months\n",
      "Created: months_overdue_count\n",
      "Created: credit_utilisation (using LIMIT_BAL and bill amounts as proxy)\n",
      "\n",
      "Shaape after creating derived features: (30001, 40)\n",
      "FINAL DATA SUMMARY\n",
      "\n",
      "Final shape: (30001, 40)\n",
      "Final columns: 40\n",
      "\n",
      "Column names:\n",
      "  1. LIMIT_BAL\n",
      "  2. AGE\n",
      "  3. PAY_0\n",
      "  4. PAY_2\n",
      "  5. PAY_3\n",
      "  6. PAY_4\n",
      "  7. PAY_5\n",
      "  8. PAY_6\n",
      "  9. BILL_AMT1\n",
      "  10. BILL_AMT2\n",
      "  11. BILL_AMT3\n",
      "  12. BILL_AMT4\n",
      "  13. BILL_AMT5\n",
      "  14. BILL_AMT6\n",
      "  15. PAY_AMT1\n",
      "  16. PAY_AMT2\n",
      "  17. PAY_AMT3\n",
      "  18. PAY_AMT4\n",
      "  19. PAY_AMT5\n",
      "  20. PAY_AMT6\n",
      "  21. default_payment_next_month\n",
      "  22. SEX_1\n",
      "  23. SEX_2\n",
      "  24. EDUCATION_1\n",
      "  25. EDUCATION_2\n",
      "  26. EDUCATION_3\n",
      "  27. EDUCATION_4\n",
      "  28. EDUCATION_5\n",
      "  29. EDUCATION_6\n",
      "  30. MARRIAGE_1\n",
      "  31. MARRIAGE_2\n",
      "  32. MARRIAGE_3\n",
      "  33. total_bills_paid_to_date\n",
      "  34. avg_bill\n",
      "  35. current_outstanding\n",
      "  36. amortised_debt\n",
      "  37. avg_overdue_months\n",
      "  38. max_overdue_months\n",
      "  39. months_overdue_count\n",
      "  40. credit_utilisation\n",
      "\n",
      "Final dtypes:\n",
      "int64       25\n",
      "bool        11\n",
      "float64      3\n",
      "category     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final missing values:\n",
      "None\n",
      "\n",
      "Dataset size validation:\n",
      "Minimum requirement: 2,500 rows - Current: 30001 rows\n",
      "Dataset size meets minimum requirement\n",
      "\n",
      "Class balance check:\n",
      "  Class distribution:\n",
      "default_payment_next_month\n",
      "0    23365\n",
      "1     6636\n",
      "Name: count, dtype: int64\n",
      "  Balance ratio: 0.284\n",
      "  Class balance is acceptable\n",
      "\n",
      "TRAIN/TEST SPLIT\n",
      "Training set: 24000 rows, 39 features\n",
      "Test set: 6001 rows, 39 features\n",
      "Training class distribution:\n",
      "default_payment_next_month\n",
      "0    18691\n",
      "1     5309\n",
      "Name: count, dtype: int64\n",
      "Test class distribution:\n",
      "default_payment_next_month\n",
      "0    4674\n",
      "1    1327\n",
      "Name: count, dtype: int64\n",
      "\n",
      "APPLYING SCALING\n",
      "Using RobustScaler (anomalies detected in data)\n",
      "Scaling applied to training and test sets\n",
      "\n",
      "FINAL SUMMARY\n",
      "Training set shape: (24000, 39)\n",
      "Test set shape: (6001, 39)\n",
      "\n",
      "Dataset ready for modeling!\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "X_train, X_test, y_train, y_test, scaler = preprocess_data(\n",
    "    'default_of_credit_card_clients.xls',\n",
    "    verbose=True,\n",
    "    split_data=True,\n",
    "    apply_scaling=True,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "639d3f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance detected: True\n",
      "\n",
      "Training Logistic Regression...\n",
      "RandomizedSearchCV best score: 0.7629\n",
      "Best params: {'solver': 'liblinear', 'max_iter': 1000, 'C': np.float64(1438.44988828766)}\n",
      "GridSearchCV best score: 0.7629\n",
      "Refined params: {'C': np.float64(2876.8997765753206), 'solver': 'liblinear'}\n",
      "\n",
      "Logistic Regression Evaluation:\n",
      "Train ROC-AUC: 0.7666\n",
      "Test ROC-AUC: 0.7484\n",
      "Train F1: 0.5268\n",
      "Test F1: 0.5094\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3672 1002]\n",
      " [ 531  796]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83      4674\n",
      "           1       0.44      0.60      0.51      1327\n",
      "\n",
      "    accuracy                           0.74      6001\n",
      "   macro avg       0.66      0.69      0.67      6001\n",
      "weighted avg       0.78      0.74      0.76      6001\n",
      "\n",
      "Logistic Regression finished, training time: 78.90s, accuracy: 0.7445\n",
      "\n",
      "Training Random Forest...\n",
      "RandomizedSearchCV best score: 0.7823\n",
      "Best params: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 10}\n",
      "GridSearchCV best score: 0.7822\n",
      "Refined params: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Random Forest Evaluation:\n",
      "Train ROC-AUC: 0.8734\n",
      "Test ROC-AUC: 0.7742\n",
      "Train F1: 0.5806\n",
      "Test F1: 0.4640\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4412  262]\n",
      " [ 847  480]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      4674\n",
      "           1       0.65      0.36      0.46      1327\n",
      "\n",
      "    accuracy                           0.82      6001\n",
      "   macro avg       0.74      0.65      0.68      6001\n",
      "weighted avg       0.80      0.82      0.79      6001\n",
      "\n",
      "Random Forest finished, training time: 327.72s, accuracy: 0.8152\n",
      "\n",
      "Training Gradient Boosting...\n",
      "RandomizedSearchCV best score: 0.7816\n",
      "Best params: {'subsample': 1.0, 'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 5, 'learning_rate': 0.1}\n",
      "GridSearchCV best score: 0.7832\n",
      "Refined params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.9}\n",
      "\n",
      "Gradient Boosting Evaluation:\n",
      "Train ROC-AUC: 0.8245\n",
      "Test ROC-AUC: 0.7786\n",
      "Train F1: 0.5263\n",
      "Test F1: 0.4627\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4403  271]\n",
      " [ 846  481]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      4674\n",
      "           1       0.64      0.36      0.46      1327\n",
      "\n",
      "    accuracy                           0.81      6001\n",
      "   macro avg       0.74      0.65      0.68      6001\n",
      "weighted avg       0.79      0.81      0.79      6001\n",
      "\n",
      "Gradient Boosting finished, training time: 144.51s, accuracy: 0.8139\n",
      "\n",
      "Training Neural Network...\n",
      "RandomizedSearchCV best score: 0.7751\n",
      "Best params: {'max_iter': 300, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (100, 50), 'alpha': 0.001}\n",
      "GridSearchCV best score: 0.7751\n",
      "Refined params: {'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'learning_rate_init': 0.001}\n",
      "\n",
      "Neural Network Evaluation:\n",
      "Train ROC-AUC: 0.7862\n",
      "Test ROC-AUC: 0.7650\n",
      "Train F1: 0.4793\n",
      "Test F1: 0.4615\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4391  283]\n",
      " [ 844  483]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      4674\n",
      "           1       0.63      0.36      0.46      1327\n",
      "\n",
      "    accuracy                           0.81      6001\n",
      "   macro avg       0.73      0.65      0.67      6001\n",
      "weighted avg       0.79      0.81      0.79      6001\n",
      "\n",
      "Neural Network finished, training time: 27.53s, accuracy: 0.8122\n",
      "\n",
      "Total training time: 578.71s, most accurate: Random Forest (0.8152)\n"
     ]
    }
   ],
   "source": [
    "# Train and tune models\n",
    "models, results = train_and_tune_models(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    use_randomized=True,\n",
    "    use_grid=True,\n",
    "    n_iter_randomized=20,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a703d80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Creating stacked model\n",
      "\n",
      "Evaluating Stacked Model...\n",
      "\n",
      "Stacked Ensemble Evaluation:\n",
      "Train ROC-AUC: 0.8292\n",
      "Test ROC-AUC: 0.7739\n",
      "Train F1: 0.5733\n",
      "Test F1: 0.5112\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4274  400]\n",
      " [ 734  593]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      4674\n",
      "           1       0.60      0.45      0.51      1327\n",
      "\n",
      "    accuracy                           0.81      6001\n",
      "   macro avg       0.73      0.68      0.70      6001\n",
      "weighted avg       0.80      0.81      0.80      6001\n",
      "\n",
      "\n",
      "Stacked Ensemble finished, accuracy: 0.8110\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Creating stacked model\")\n",
    "stacked_model = create_stacked_model(models, X_train, y_train, random_state=42, calibrate=False)\n",
    "\n",
    "# Add stacked model to models dictionary\n",
    "models['stacked_model'] = stacked_model\n",
    "\n",
    "# Evaluate stacked model\n",
    "print(\"\\nEvaluating Stacked Model...\")\n",
    "stacked_results = evaluate_model( \n",
    "    stacked_model, X_train, y_train, X_test, y_test, \"Stacked Ensemble\", verbose=True\n",
    ")\n",
    "\n",
    "# Add to results dictionary\n",
    "results['stacked_model'] = stacked_results\n",
    "\n",
    "stacked_accuracy = accuracy_score(y_test, stacked_model.predict(X_test))\n",
    "print(f\"\\nStacked Ensemble finished, accuracy: {stacked_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "615a6930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Evaluation (Same Folds for All Models)\n",
      "\n",
      "Logistic Regression:\n",
      "  ROC-AUC: 0.7629  0.0064\n",
      "  PR-AUC:  0.5176  0.0100\n",
      "\n",
      "Random Forest:\n",
      "  ROC-AUC: 0.7822  0.0052\n",
      "  PR-AUC:  0.5617  0.0100\n",
      "\n",
      "Gradient Boosting:\n",
      "  ROC-AUC: 0.7832  0.0055\n",
      "  PR-AUC:  0.5615  0.0085\n",
      "\n",
      "Neural Network:\n",
      "  ROC-AUC: 0.7751  0.0082\n",
      "  PR-AUC:  0.5445  0.0134\n",
      "\n",
      "Stacked Ensemble:\n",
      "  ROC-AUC: 0.7829  0.0053\n",
      "  PR-AUC:  0.5624  0.0077\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation evaluation\n",
    "cv_results = cross_validate_models(models, X_train, y_train, cv=5, random_state=42, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6be5b341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistical Model Comparison\n",
      "\n",
      "Logistic Regression vs Random Forest:\n",
      "  McNemar's test: chi2=168.4831, p=0.0000\n",
      "  Paired t-test: t=-8.2496, p=0.0012\n",
      "\n",
      "Logistic Regression vs Gradient Boosting:\n",
      "  McNemar's test: chi2=163.4013, p=0.0000\n",
      "  Paired t-test: t=-8.9105, p=0.0009\n",
      "\n",
      "Logistic Regression vs Neural Network:\n",
      "  McNemar's test: chi2=158.3253, p=0.0000\n",
      "  Paired t-test: t=-5.1306, p=0.0068\n",
      "\n",
      "Logistic Regression vs stacked_model:\n",
      "  McNemar's test: chi2=195.3194, p=0.0000\n",
      "  Paired t-test: t=-13.4064, p=0.0002\n",
      "\n",
      "Random Forest vs Gradient Boosting:\n",
      "  McNemar's test: chi2=0.4623, p=0.4966\n",
      "  Paired t-test: t=-0.9865, p=0.3797\n",
      "\n",
      "Random Forest vs Neural Network:\n",
      "  McNemar's test: chi2=1.9527, p=0.1623\n",
      "  Paired t-test: t=2.8253, p=0.0476\n",
      "\n",
      "Random Forest vs stacked_model:\n",
      "  McNemar's test: chi2=2.2588, p=0.1329\n",
      "  Paired t-test: t=-0.8038, p=0.4666\n",
      "\n",
      "Gradient Boosting vs Neural Network:\n",
      "  McNemar's test: chi2=0.5192, p=0.4712\n",
      "  Paired t-test: t=2.7460, p=0.0516\n",
      "\n",
      "Gradient Boosting vs stacked_model:\n",
      "  McNemar's test: chi2=1.0535, p=0.3047\n",
      "  Paired t-test: t=0.3066, p=0.7744\n",
      "\n",
      "Neural Network vs stacked_model:\n",
      "  McNemar's test: chi2=0.1348, p=0.7135\n",
      "  Paired t-test: t=-3.3147, p=0.0295\n"
     ]
    }
   ],
   "source": [
    "# Statistical model comparison\n",
    "stat_results = statistical_comparison(models, X_test, y_test, cv_results=cv_results, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d923a591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Comprehensive Evaluation\n",
      "\n",
      "ROC-AUC: 0.7484\n",
      "Overall discrimination ability\n",
      "\n",
      "Precision: 0.4427\n",
      "Recall: 0.5998\n",
      "F1 Score: 0.5094\n",
      "Important when default is minority class or false negatives are costly\n",
      "\n",
      "PR-AUC: 0.5056\n",
      "Precision-Recall AUC - better than ROC-AUC for class imbalance\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              No Default  Default\n",
      "Actual No Default     3672      1002\n",
      "       Default         531       796\n",
      "\n",
      "False Positives: 1002\n",
      "False Negatives: 531\n",
      "\n",
      "Brier Score: 0.1944\n",
      "Lower is better - measures probabilistic prediction quality\n",
      "\n",
      "Cost Analysis:\n",
      "Cost per False Positive: $100.00\n",
      "Cost per False Negative: $5,000.00\n",
      "Total False Positives: 1002\n",
      "Total False Negatives: 531\n",
      "Total Business Cost: $2,755,200.00\n",
      "Cost per Prediction: $459.12\n",
      "\n",
      "Potential writeoff (if all defaults missed): $2,655,000.00\n",
      "Potential payback (if all correctly identified): $3,980,000.00\n",
      "\n",
      "Random Forest Comprehensive Evaluation\n",
      "\n",
      "ROC-AUC: 0.7742\n",
      "Overall discrimination ability\n",
      "\n",
      "Precision: 0.6469\n",
      "Recall: 0.3617\n",
      "F1 Score: 0.4640\n",
      "Important when default is minority class or false negatives are costly\n",
      "\n",
      "PR-AUC: 0.5505\n",
      "Precision-Recall AUC - better than ROC-AUC for class imbalance\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              No Default  Default\n",
      "Actual No Default     4412       262\n",
      "       Default         847       480\n",
      "\n",
      "False Positives: 262\n",
      "False Negatives: 847\n",
      "\n",
      "Brier Score: 0.1361\n",
      "Lower is better - measures probabilistic prediction quality\n",
      "\n",
      "Cost Analysis:\n",
      "Cost per False Positive: $100.00\n",
      "Cost per False Negative: $5,000.00\n",
      "Total False Positives: 262\n",
      "Total False Negatives: 847\n",
      "Total Business Cost: $4,261,200.00\n",
      "Cost per Prediction: $710.08\n",
      "\n",
      "Potential writeoff (if all defaults missed): $4,235,000.00\n",
      "Potential payback (if all correctly identified): $2,400,000.00\n",
      "\n",
      "Gradient Boosting Comprehensive Evaluation\n",
      "\n",
      "ROC-AUC: 0.7786\n",
      "Overall discrimination ability\n",
      "\n",
      "Precision: 0.6396\n",
      "Recall: 0.3625\n",
      "F1 Score: 0.4627\n",
      "Important when default is minority class or false negatives are costly\n",
      "\n",
      "PR-AUC: 0.5503\n",
      "Precision-Recall AUC - better than ROC-AUC for class imbalance\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              No Default  Default\n",
      "Actual No Default     4403       271\n",
      "       Default         846       481\n",
      "\n",
      "False Positives: 271\n",
      "False Negatives: 846\n",
      "\n",
      "Brier Score: 0.1358\n",
      "Lower is better - measures probabilistic prediction quality\n",
      "\n",
      "Cost Analysis:\n",
      "Cost per False Positive: $100.00\n",
      "Cost per False Negative: $5,000.00\n",
      "Total False Positives: 271\n",
      "Total False Negatives: 846\n",
      "Total Business Cost: $4,257,100.00\n",
      "Cost per Prediction: $709.40\n",
      "\n",
      "Potential writeoff (if all defaults missed): $4,230,000.00\n",
      "Potential payback (if all correctly identified): $2,405,000.00\n",
      "\n",
      "Neural Network Comprehensive Evaluation\n",
      "\n",
      "ROC-AUC: 0.7650\n",
      "Overall discrimination ability\n",
      "\n",
      "Precision: 0.6305\n",
      "Recall: 0.3640\n",
      "F1 Score: 0.4615\n",
      "Important when default is minority class or false negatives are costly\n",
      "\n",
      "PR-AUC: 0.5345\n",
      "Precision-Recall AUC - better than ROC-AUC for class imbalance\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              No Default  Default\n",
      "Actual No Default     4391       283\n",
      "       Default         844       483\n",
      "\n",
      "False Positives: 283\n",
      "False Negatives: 844\n",
      "\n",
      "Brier Score: 0.1386\n",
      "Lower is better - measures probabilistic prediction quality\n",
      "\n",
      "Cost Analysis:\n",
      "Cost per False Positive: $100.00\n",
      "Cost per False Negative: $5,000.00\n",
      "Total False Positives: 283\n",
      "Total False Negatives: 844\n",
      "Total Business Cost: $4,248,300.00\n",
      "Cost per Prediction: $707.93\n",
      "\n",
      "Potential writeoff (if all defaults missed): $4,220,000.00\n",
      "Potential payback (if all correctly identified): $2,415,000.00\n",
      "\n",
      "Stacked Ensemble Comprehensive Evaluation\n",
      "\n",
      "ROC-AUC: 0.7739\n",
      "Overall discrimination ability\n",
      "\n",
      "Precision: 0.5972\n",
      "Recall: 0.4469\n",
      "F1 Score: 0.5112\n",
      "Important when default is minority class or false negatives are costly\n",
      "\n",
      "PR-AUC: 0.5479\n",
      "Precision-Recall AUC - better than ROC-AUC for class imbalance\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              No Default  Default\n",
      "Actual No Default     4274       400\n",
      "       Default         734       593\n",
      "\n",
      "False Positives: 400\n",
      "False Negatives: 734\n",
      "\n",
      "Brier Score: 0.1424\n",
      "Lower is better - measures probabilistic prediction quality\n",
      "\n",
      "Cost Analysis:\n",
      "Cost per False Positive: $100.00\n",
      "Cost per False Negative: $5,000.00\n",
      "Total False Positives: 400\n",
      "Total False Negatives: 734\n",
      "Total Business Cost: $3,710,000.00\n",
      "Cost per Prediction: $618.23\n",
      "\n",
      "Potential writeoff (if all defaults missed): $3,670,000.00\n",
      "Potential payback (if all correctly identified): $2,965,000.00\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive evaluation\n",
    "for model_name, model in models.items():\n",
    "    display_name = {\n",
    "        'logistic_regression': 'Logistic Regression',\n",
    "        'random_forest': 'Random Forest',\n",
    "        'gradient_boosting': 'Gradient Boosting',\n",
    "        'neural_network': 'Neural Network',\n",
    "        'stacked_model': 'Stacked Ensemble'\n",
    "    }.get(model_name, model_name)\n",
    "    \n",
    "    comprehensive_evaluation(\n",
    "        model, X_test, y_test, \n",
    "        model_name=display_name,\n",
    "        cost_false_positive=100,\n",
    "        cost_false_negative=5000,\n",
    "        verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "287b95e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing Logistic Regression...\n",
      "Saved feature importance plot to results/Logistic Regression_feature_importance.png\n",
      "Saved SHAP summary plot to results/Logistic Regression_shap_summary.png\n",
      "Saved SHAP bar plot to results/Logistic Regression_shap_bar.png\n",
      "\n",
      "Analyzing Random Forest...\n",
      "Saved feature importance plot to results/Random Forest_feature_importance.png\n",
      "Saved SHAP summary plot to results/Random Forest_shap_summary.png\n",
      "Saved SHAP bar plot to results/Random Forest_shap_bar.png\n",
      "\n",
      "Analyzing Gradient Boosting...\n",
      "Saved feature importance plot to results/Gradient Boosting_feature_importance.png\n",
      "Saved SHAP summary plot to results/Gradient Boosting_shap_summary.png\n",
      "Saved SHAP bar plot to results/Gradient Boosting_shap_bar.png\n",
      "\n",
      "Analyzing Neural Network...\n",
      "Saved feature importance plot to results/Neural Network_feature_importance.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:32<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SHAP summary plot to results/Neural Network_shap_summary.png\n",
      "Saved SHAP bar plot to results/Neural Network_shap_bar.png\n",
      "\n",
      "Analyzing Stacked Ensemble...\n",
      "Saved feature importance plot to results/Stacked Ensemble_feature_importance.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [01:12<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SHAP summary plot to results/Stacked Ensemble_shap_summary.png\n",
      "Saved SHAP bar plot to results/Stacked Ensemble_shap_bar.png\n"
     ]
    }
   ],
   "source": [
    "# Feature importance and SHAP analysis\n",
    "for model_name, model in models.items():\n",
    "    display_name = {\n",
    "        'logistic_regression': 'Logistic Regression',\n",
    "        'random_forest': 'Random Forest',\n",
    "        'gradient_boosting': 'Gradient Boosting',\n",
    "        'neural_network': 'Neural Network',\n",
    "        'stacked_model': 'Stacked Ensemble'\n",
    "    }.get(model_name, model_name)\n",
    "    \n",
    "    print(f\"\\nAnalyzing {display_name}...\")\n",
    "    plot_feature_importance_and_shap(\n",
    "        model, X_train, X_test, X_train.columns.tolist(),\n",
    "        model_name=display_name, top_n=20, save_plots=True, y_test=y_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4d0f7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE PREDICTIONS\n",
      "\n",
      "Case 1: Low Risk Customer\n",
      "Logistic Regression: Default=0.3583 (35.83%), Payback=0.6417 (64.17%)\n",
      "Random Forest: Default=0.1361 (13.61%), Payback=0.8639 (86.39%)\n",
      "Gradient Boosting: Default=0.1513 (15.13%), Payback=0.8487 (84.87%)\n",
      "Neural Network: Default=0.1506 (15.06%), Payback=0.8494 (84.94%)\n",
      "Stacked Ensemble: Default=0.2152 (21.52%), Payback=0.7848 (78.48%)\n",
      "\n",
      "Average across all models:\n",
      "  Probability of DEFAULT: 0.2023 (20.23%)\n",
      "  Probability of PAYING BACK: 0.7977 (79.77%)\n",
      "  Prediction: WILL PAY BACK (risk threshold: 50%)\n",
      "\n",
      "Case 2: Medium Risk Customer\n",
      "Logistic Regression: Default=0.6543 (65.43%), Payback=0.3457 (34.57%)\n",
      "Random Forest: Default=0.2454 (24.54%), Payback=0.7546 (75.46%)\n",
      "Gradient Boosting: Default=0.2104 (21.04%), Payback=0.7896 (78.96%)\n",
      "Neural Network: Default=0.4065 (40.65%), Payback=0.5935 (59.35%)\n",
      "Stacked Ensemble: Default=0.3701 (37.01%), Payback=0.6299 (62.99%)\n",
      "\n",
      "Average across all models:\n",
      "  Probability of DEFAULT: 0.3773 (37.73%)\n",
      "  Probability of PAYING BACK: 0.6227 (62.27%)\n",
      "  Prediction: WILL PAY BACK (risk threshold: 50%)\n",
      "\n",
      "Case 3: High Risk Customer\n",
      "Logistic Regression: Default=0.7811 (78.11%), Payback=0.2189 (21.89%)\n",
      "Random Forest: Default=0.6467 (64.67%), Payback=0.3533 (35.33%)\n",
      "Gradient Boosting: Default=0.7569 (75.69%), Payback=0.2431 (24.31%)\n",
      "Neural Network: Default=0.6860 (68.60%), Payback=0.3140 (31.40%)\n",
      "Stacked Ensemble: Default=0.7282 (72.82%), Payback=0.2718 (27.18%)\n",
      "\n",
      "Average across all models:\n",
      "  Probability of DEFAULT: 0.7198 (71.98%)\n",
      "  Probability of PAYING BACK: 0.2802 (28.02%)\n",
      "  Prediction: WILL DEFAULT (risk threshold: 50%)\n",
      "\n",
      "Case 4: Very High Risk Customer\n",
      "Logistic Regression: Default=0.9459 (94.59%), Payback=0.0541 (5.41%)\n",
      "Random Forest: Default=0.6736 (67.36%), Payback=0.3264 (32.64%)\n",
      "Gradient Boosting: Default=0.7274 (72.74%), Payback=0.2726 (27.26%)\n",
      "Neural Network: Default=0.8607 (86.07%), Payback=0.1393 (13.93%)\n",
      "Stacked Ensemble: Default=0.7823 (78.23%), Payback=0.2177 (21.77%)\n",
      "\n",
      "Average across all models:\n",
      "  Probability of DEFAULT: 0.7980 (79.80%)\n",
      "  Probability of PAYING BACK: 0.2020 (20.20%)\n",
      "  Prediction: WILL DEFAULT (risk threshold: 50%)\n",
      "\n",
      "Case 5: Recovering Customer\n",
      "Logistic Regression: Default=0.7844 (78.44%), Payback=0.2156 (21.56%)\n",
      "Random Forest: Default=0.3287 (32.87%), Payback=0.6713 (67.13%)\n",
      "Gradient Boosting: Default=0.3802 (38.02%), Payback=0.6198 (61.98%)\n",
      "Neural Network: Default=0.3824 (38.24%), Payback=0.6176 (61.76%)\n",
      "Stacked Ensemble: Default=0.4978 (49.78%), Payback=0.5022 (50.22%)\n",
      "\n",
      "Average across all models:\n",
      "  Probability of DEFAULT: 0.4747 (47.47%)\n",
      "  Probability of PAYING BACK: 0.5253 (52.53%)\n",
      "  Prediction: WILL PAY BACK (risk threshold: 50%)\n"
     ]
    }
   ],
   "source": [
    "print(\"EXAMPLE PREDICTIONS\")\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        'name': 'Case 1: Low Risk Customer',\n",
    "        'LIMIT_BAL': 20000, 'SEX': 2, 'EDUCATION': 2, 'MARRIAGE': 1, 'AGE': 30,\n",
    "        'PAY_0': 0, 'PAY_2': 0, 'PAY_3': 0, 'PAY_4': 0, 'PAY_5': 0, 'PAY_6': 0,\n",
    "        'BILL_AMT1': 5000, 'BILL_AMT2': 4500, 'BILL_AMT3': 4000, 'BILL_AMT4': 3500, 'BILL_AMT5': 3000, 'BILL_AMT6': 2500,\n",
    "        'PAY_AMT1': 2000, 'PAY_AMT2': 2000, 'PAY_AMT3': 2000, 'PAY_AMT4': 2000, 'PAY_AMT5': 2000, 'PAY_AMT6': 2000\n",
    "    },\n",
    "    {\n",
    "        'name': 'Case 2: Medium Risk Customer',\n",
    "        'LIMIT_BAL': 15000, 'SEX': 1, 'EDUCATION': 3, 'MARRIAGE': 2, 'AGE': 35,\n",
    "        'PAY_0': 1, 'PAY_2': 0, 'PAY_3': 1, 'PAY_4': 0, 'PAY_5': 0, 'PAY_6': 0,\n",
    "        'BILL_AMT1': 12000, 'BILL_AMT2': 11000, 'BILL_AMT3': 10000, 'BILL_AMT4': 9000, 'BILL_AMT5': 8000, 'BILL_AMT6': 7000,\n",
    "        'PAY_AMT1': 3000, 'PAY_AMT2': 2500, 'PAY_AMT3': 2000, 'PAY_AMT4': 2000, 'PAY_AMT5': 1500, 'PAY_AMT6': 1500\n",
    "    },\n",
    "    {\n",
    "        'name': 'Case 3: High Risk Customer',\n",
    "        'LIMIT_BAL': 10000, 'SEX': 1, 'EDUCATION': 4, 'MARRIAGE': 3, 'AGE': 45,\n",
    "        'PAY_0': 2, 'PAY_2': 2, 'PAY_3': 1, 'PAY_4': 1, 'PAY_5': 0, 'PAY_6': 0,\n",
    "        'BILL_AMT1': 9500, 'BILL_AMT2': 9000, 'BILL_AMT3': 8500, 'BILL_AMT4': 8000, 'BILL_AMT5': 7500, 'BILL_AMT6': 7000,\n",
    "        'PAY_AMT1': 500, 'PAY_AMT2': 500, 'PAY_AMT3': 1000, 'PAY_AMT4': 1000, 'PAY_AMT5': 500, 'PAY_AMT6': 500\n",
    "    },\n",
    "    {\n",
    "        'name': 'Case 4: Very High Risk Customer',\n",
    "        'LIMIT_BAL': 50000, 'SEX': 2, 'EDUCATION': 1, 'MARRIAGE': 1, 'AGE': 28,\n",
    "        'PAY_0': 3, 'PAY_2': 3, 'PAY_3': 2, 'PAY_4': 2, 'PAY_5': 1, 'PAY_6': 1,\n",
    "        'BILL_AMT1': 48000, 'BILL_AMT2': 47000, 'BILL_AMT3': 46000, 'BILL_AMT4': 45000, 'BILL_AMT5': 44000, 'BILL_AMT6': 43000,\n",
    "        'PAY_AMT1': 1000, 'PAY_AMT2': 1000, 'PAY_AMT3': 1000, 'PAY_AMT4': 1000, 'PAY_AMT5': 1000, 'PAY_AMT6': 1000\n",
    "    },\n",
    "    {\n",
    "        'name': 'Case 5: Recovering Customer',\n",
    "        'LIMIT_BAL': 30000, 'SEX': 1, 'EDUCATION': 2, 'MARRIAGE': 1, 'AGE': 40,\n",
    "        'PAY_0': 0, 'PAY_2': 0, 'PAY_3': 1, 'PAY_4': 1, 'PAY_5': 2, 'PAY_6': 2,\n",
    "        'BILL_AMT1': 8000, 'BILL_AMT2': 10000, 'BILL_AMT3': 12000, 'BILL_AMT4': 14000, 'BILL_AMT5': 16000, 'BILL_AMT6': 18000,\n",
    "        'PAY_AMT1': 5000, 'PAY_AMT2': 5000, 'PAY_AMT3': 5000, 'PAY_AMT4': 5000, 'PAY_AMT5': 5000, 'PAY_AMT6': 5000\n",
    "    }\n",
    "]\n",
    "\n",
    "feature_names_list = X_train.columns.tolist()\n",
    "\n",
    "for case in test_cases:\n",
    "    case_name = case.pop('name')\n",
    "    print(f\"\\n{case_name}\")\n",
    "\n",
    "    probabilities = {}\n",
    "    for model_name, model in models.items():\n",
    "        display_name = {\n",
    "            'logistic_regression': 'Logistic Regression',\n",
    "            'random_forest': 'Random Forest',\n",
    "            'gradient_boosting': 'Gradient Boosting',\n",
    "            'neural_network': 'Neural Network',\n",
    "            'stacked_model': 'Stacked Ensemble'\n",
    "        }.get(model_name, model_name)\n",
    "\n",
    "        prob_default = predict_default_probability(\n",
    "            model,\n",
    "            feature_names=feature_names_list,\n",
    "            scaler=scaler,\n",
    "            **case\n",
    "        )\n",
    "        probabilities[display_name] = prob_default\n",
    "        prob_payback = 1 - prob_default\n",
    "        print(f\"{display_name}: Default={prob_default:.4f} ({prob_default*100:.2f}%), Payback={prob_payback:.4f} ({prob_payback*100:.2f}%)\")\n",
    "\n",
    "    avg_prob_default = np.mean(list(probabilities.values()))\n",
    "    avg_prob_payback = 1 - avg_prob_default\n",
    "    \n",
    "    print(f\"\\nAverage across all models:\")\n",
    "    print(f\"  Probability of DEFAULT: {avg_prob_default:.4f} ({avg_prob_default*100:.2f}%)\")\n",
    "    print(f\"  Probability of PAYING BACK: {avg_prob_payback:.4f} ({avg_prob_payback*100:.2f}%)\")\n",
    "    \n",
    "    if avg_prob_default >= 0.5:\n",
    "        print(f\"  Prediction: WILL DEFAULT (risk threshold: 50%)\")\n",
    "    else:\n",
    "        print(f\"  Prediction: WILL PAY BACK (risk threshold: 50%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
